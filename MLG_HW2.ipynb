{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7bfe866-5253-46c1-909a-b312289edf07",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MLG HW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a50480a-8387-4943-99b7-53f156fa6e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rita/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, time, torch, json\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# from torch_geometric.utils import accuracy,sparse_mx_to_torch_sparse_tensor\n",
    "import torch_geometric.utils \n",
    "# from models.GCN import GCN\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm, trange\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data as Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# test \n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "709c4b57-737c-4780-a5f6-fbc684fb92e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "       id    to  from\n",
      "0  E10559  2323  2673\n",
      "1   E4849    81  1634\n",
      "       id    to  from  label\n",
      "0  E10311  2399  2339      0\n",
      "1  E10255  2397  1144      1\n",
      "     to  from\n",
      "0  2397  1144\n",
      "1  2450  1312\n",
      "       id  prob\n",
      "0  E10559   0.5\n",
      "1   E4849   0.5\n"
     ]
    }
   ],
   "source": [
    "content = []\n",
    "test = []\n",
    "train = []\n",
    "upload = []\n",
    "edge_index = [] \n",
    "for i in range(3):\n",
    "    os.chdir('/home/rita/111/111-2MLG/HW2/dataset{}'.format(i + 1))\n",
    "    temp = pd.read_csv('./content.csv', header = None, sep = '\\t')\n",
    "    temp.sort_values(by = [0], inplace = True)\n",
    "    temp.set_index([0], inplace = True)\n",
    "    temp = torch.Tensor(np.array(temp)).to(torch.float32)\n",
    "    content.append(temp)\n",
    "    test.append(pd.read_csv('./test.csv'))\n",
    "    temp = pd.read_csv('./train.csv')\n",
    "    train.append(temp)\n",
    "    temp = temp[temp.label == 1]\n",
    "    temp = temp[['to', 'from']]\n",
    "    temp = temp.reset_index(drop = True)\n",
    "    edge_index.append(temp)\n",
    "    upload.append(pd.read_csv('./upload.csv'))\n",
    "print(content[0][:2])\n",
    "print(test[0].head(2))\n",
    "print(train[0].head(2))\n",
    "print(edge_index[0].head(2))\n",
    "print(upload[0].head(2))\n",
    "os.chdir('/home/rita/111/111-2MLG/HW2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62afbac7-fa3e-4c9f-b7d3-9ea9f1cf4ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# content preprocessing\n",
    "new_features = []\n",
    "for i in range(len(content)) :\n",
    "    t = content[i]\n",
    "    features_entropy = []\n",
    "    for i in range(t.shape[1]) :\n",
    "        temp = t.T[i]\n",
    "        t1 = torch.sum(temp == 0) / len(temp)\n",
    "        t2 = torch.sum(temp == 1) / len(temp)\n",
    "        temp = torch.tensor([t1, t2])\n",
    "        temp = entropy(temp)\n",
    "        if (temp == 0) :\n",
    "            temp = 0\n",
    "        else :\n",
    "            temp = 1 / temp\n",
    "        features_entropy.append(temp)\n",
    "    features_entropy = torch.tensor(features_entropy).reshape(1, -1)\n",
    "    t = t * features_entropy\n",
    "    t = t.type(torch.float32)\n",
    "    new_features.append(t)\n",
    "print(new_features[0][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce7cd1c5-5478-4bd9-a400-d22f767ace87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class link_predict(nn.Module) :\n",
    "    def __init__(self, features, emb_dim = 128) :\n",
    "        super(link_predict, self).__init__()\n",
    "        self.features = features\n",
    "        self.edge_index = edge_index\n",
    "        self.emb_dim = emb_dim\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(self.features.shape[1], self.emb_dim), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(self.emb_dim, self.emb_dim // 2), \n",
    "            # nn.ReLU(), \n",
    "            # nn.Linear(self.emb_dim // 2, self.emb_dim // 4)\n",
    "        )\n",
    "        # self.poten_edges = self.get_poten_edges(fearures)\n",
    "        \n",
    "    def forward(self, want_edge) :\n",
    "        z = self.mlp(self.features)\n",
    "        out = []\n",
    "        for i in range(want_edge.shape[0]) :\n",
    "            idx1 = want_edge[i, 0].type(torch.LongTensor)\n",
    "            idx2 = want_edge[i, 1].type(torch.LongTensor)\n",
    "            temp = (z[idx1] * z[idx2]).sum()\n",
    "            # temp = torch.matmul(z[idx1], z[idx2].T)\n",
    "            # temp = temp if temp > 0 else 0\n",
    "            temp = temp - torch.mean(temp)\n",
    "            sig = nn.Sigmoid()\n",
    "            temp = sig(temp)\n",
    "            out.append(temp)\n",
    "        return torch.tensor(out).reshape(-1, 1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20d78c7e-c0dc-48a0-9097-9b8a43d8fd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\") #可以根據輸出結果知道是否有可用的GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4bc8f49-2796-4aaf-803f-03ab492cc29d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_loop(model, n_epochs, optimizer, loss_fn, features, train_loader, sigma, val_loader = None) :\n",
    "    ls_train_loss = []\n",
    "    ls_val_loss = []\n",
    "    features = features.to(torch.float32).to(device = device)\n",
    "    for epoch in range(1, n_epochs + 1) :  \n",
    "        val_loss = 0\n",
    "        loop = tqdm(enumerate(train_loader), total = len(train_loader))\n",
    "        for i, (edge, labels) in loop :\n",
    "            poten = get_poten_edges(features, edge)\n",
    "            edge = edge.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(edge).to(device)            \n",
    "            loss = 0\n",
    "            for j in range(labels.shape[0]) :\n",
    "                if(labels[j] == 1):\n",
    "                    loss += torch.exp(-(poten[j]/sigma**2)) * loss_fn(outputs[j], labels[j])\n",
    "                    loss /= labels.shape[0]\n",
    "                else :\n",
    "                    loss += torch.exp((poten[j]/sigma**2)) * loss_fn(outputs[j], labels[j])     \n",
    "                    loss /= labels.shape[0]\n",
    "                \n",
    "            loss.requires_grad_()\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "            loop.set_description(f'Epoch[{epoch} / {n_epochs}]')\n",
    "            if (val_loader != None):\n",
    "                if (i+1 == len(train_loader)) :\n",
    "                    val_loss = validate(model, loss_fn, val_loader)\n",
    "                loop.set_postfix(loss = loss, val_loss = val_loss)\n",
    "            else :\n",
    "                loop.set_postfix(loss = loss)\n",
    "        ls_train_loss.append(loss.item()) \n",
    "    \n",
    "    return ls_train_loss\n",
    "        \n",
    "def get_poten_edges(features, edge) :\n",
    "    poten_edges = []\n",
    "    \n",
    "    for i in range(edge.shape[0]) :\n",
    "        idx1 = edge[i, 0].type(torch.LongTensor)\n",
    "        idx2 = edge[i, 1].type(torch.LongTensor)\n",
    "        temp = (features[idx1] - features[idx2]) ** 2\n",
    "        temp = torch.sum((features[idx1] - features[idx2]) ** 2)\n",
    "        # print(temp)\n",
    "        # temp = (features[idx1] == features[idx2]).sum() \n",
    "        poten_edges.append(temp)\n",
    "    temp -= temp.min()        \n",
    "    return torch.tensor(poten_edges)    \n",
    "\n",
    "def validate(model, loss_fn, loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss = 0\n",
    "    with torch.no_grad(): \n",
    "        for edges, labels in loader:\n",
    "            poten = get_poten_edges(features, edges)\n",
    "            edges = edges.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(edges).to(device)  \n",
    "            total += labels.shape[0] \n",
    "            for i in range(labels.shape[0]) :\n",
    "                if(labels[i] == 1):\n",
    "                    loss += torch.exp(-(poten[i]/sigma**2)) * loss_fn(outputs[i], labels[i])\n",
    "                else :\n",
    "                    loss += torch.exp((poten[i]/sigma**2)) * loss_fn(outputs[i], labels[i])     \n",
    "    loss /= total       \n",
    "   \n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615a4771-d3ab-4e48-a207-8e105b157e61",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d4d51b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[1 / 5]: 100%|██████████| 91/91 [00:04<00:00, 18.88it/s, loss=tensor(0.0048, device='cuda:0', requires_grad=True), val_loss=tensor(7.2523, device='cuda:0')]\n",
      "Epoch[2 / 5]: 100%|██████████| 91/91 [00:04<00:00, 19.10it/s, loss=tensor(0.0043, device='cuda:0', requires_grad=True), val_loss=tensor(7.2568, device='cuda:0')]\n",
      "Epoch[3 / 5]: 100%|██████████| 91/91 [00:05<00:00, 17.72it/s, loss=tensor(0.0044, device='cuda:0', requires_grad=True), val_loss=tensor(7.2530, device='cuda:0')]\n",
      "Epoch[4 / 5]: 100%|██████████| 91/91 [00:05<00:00, 17.24it/s, loss=tensor(0.0043, device='cuda:0', requires_grad=True), val_loss=tensor(7.2537, device='cuda:0')]\n",
      "Epoch[5 / 5]: 100%|██████████| 91/91 [00:04<00:00, 20.00it/s, loss=tensor(0.0043, device='cuda:0', requires_grad=True), val_loss=tensor(7.2543, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.027231216430664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "model = link_predict(content[0].to(device)).to(device)\n",
    "# L2 regularization\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay = 1e-5)  \n",
    "loss_fn = nn.MSELoss()\n",
    "n_epochs = 5\n",
    "features = new_features[0]\n",
    "train_data = train[0]\n",
    "train_label = torch.Tensor(np.array(train_data.iloc[::, -1])).to(torch.float32)\n",
    "train_data = torch.Tensor(np.array(train_data.iloc[::, [1, 2]])).to(torch.float32)\n",
    "train_data, val_data, train_label, val_label = train_test_split(train_data, train_label, test_size=0.33, random_state=42)\n",
    "train_dataset = Data.TensorDataset(train_data, train_label)\n",
    "val_dataset = Data.TensorDataset(val_data, val_label)\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = 4\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset = val_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = 4\n",
    ")\n",
    "sigma = 100\n",
    "\n",
    "ls_loss = training_loop( \n",
    "    model = model, \n",
    "    n_epochs = n_epochs,\n",
    "    optimizer = optimizer,\n",
    "    loss_fn = loss_fn,\n",
    "    features = features, \n",
    "    train_loader = train_loader, \n",
    "    val_loader = val_loader, \n",
    "    # val_loader = None, \n",
    "    sigma = sigma\n",
    ")\n",
    "print(time.time() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12730f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(features, train, n_epochs = 100, batch_size = 64, sigma = 100, val = True) :\n",
    "    model = link_predict(features.to(device)).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay = 1e-5)  \n",
    "    loss_fn = nn.MSELoss()\n",
    "    train_y = torch.Tensor(np.array(train.iloc[::, -1])).to(torch.float32)\n",
    "    train_x = torch.Tensor(np.array(train.iloc[::, [1, 2]])).to(torch.float32)\n",
    "    if val :\n",
    "        train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.33, random_state=42)\n",
    "        train_dataset = Data.TensorDataset(train_x, train_y)\n",
    "        val_dataset = Data.TensorDataset(val_x, val_y)\n",
    "        val_loader = DataLoader(\n",
    "            dataset = val_dataset,\n",
    "            batch_size = batch_size,\n",
    "            shuffle = True,\n",
    "            num_workers = 4\n",
    "        )\n",
    "    train_loader = DataLoader(\n",
    "        dataset = train_dataset,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True,\n",
    "        num_workers = 4\n",
    "    )\n",
    "    \n",
    "    ls_loss = training_loop( \n",
    "        model = model, \n",
    "        n_epochs = n_epochs,\n",
    "        optimizer = optimizer,\n",
    "        loss_fn = loss_fn,\n",
    "        features = features, \n",
    "        train_loader = train_loader, \n",
    "        val_loader = val, \n",
    "        sigma = sigma\n",
    "    )\n",
    "    return model, ls_loss\n",
    "\n",
    "def predict(model, test) :\n",
    "    test_x = torch.Tensor(np.array(test.iloc[::, 1:])).to(device)\n",
    "    test_y = model(test_x)\n",
    "    test_y = pd.DataFrame(test_y)\n",
    "    pred = pd.concat([test, test_y], axis = 1)\n",
    "    pred = pred.drop(['to', 'from'], axis = 1)\n",
    "    pred.columns = ['id', 'prob']\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1084f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "n_epochs = 50\n",
    "batch_size = 64\n",
    "for i in range(3) :\n",
    "    features = new_features[i]\n",
    "    train_x = train[i]\n",
    "    test_x = test[i]\n",
    "    model = link_predict(features.to(device)).to(device)\\\n",
    "    model, ls_loss = save(\n",
    "        features = features, \n",
    "        train = train_x, \n",
    "        n_epochs = n_epochs, \n",
    "        batch_size = batch_size, \n",
    "        sigma = 100\n",
    "        val = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c964979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "0.75\n",
      "0.8333333333333333\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "# mAUC: sklearn.metrics.roc_auc_score\n",
    "# mAP: sklearn.metrics.average_precision_score\n",
    "# Final = (mAUC+mAP)/2\n",
    "\n",
    "# example1\n",
    "y_true = np.array([0, 0, 1, 1])\n",
    "print(y_true.shape)\n",
    "y_predprob = np.array([[0.9, 0.1], [0.6, 0.4], [0.65, 0.35], [0.2, 0.8]])\n",
    "y_scores = y_predprob[:, 1]\n",
    "print(roc_auc_score(y_true, y_scores))\n",
    "print(average_precision_score(y_true, y_scores))\n",
    "\n",
    "# train\n",
    "n_epochs = 50\n",
    "batch_size = 64\n",
    "for i in range(3) :\n",
    "    features = new_features[i]\n",
    "    train_x = train[i]\n",
    "    train_y = torch.Tensor(np.array(train_x.iloc[::, -1])).to(torch.float32)\n",
    "    train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.33, random_state=42)\n",
    "    model = link_predict(features.to(device)).to(device)\\\n",
    "    model, ls_loss = save(\n",
    "        features = features, \n",
    "        train = train_x, \n",
    "        n_epochs = n_epochs, \n",
    "        batch_size = batch_size, \n",
    "        sigma = 100\n",
    "        val = True\n",
    "    )\n",
    "    pred = predict(\n",
    "        model = model, \n",
    "        test = val_x\n",
    "    )\n",
    "    pred = pred[::, -1]\n",
    "    print()\n",
    "\n",
    "\n",
    "# check (mAUC+mAP)/2\n",
    "for i in range(3) :\n",
    "    features = new_features[i]\n",
    "    test_x = test[i]\n",
    "    loaded_model = link_predict(features.to(device)).to(device)\n",
    "    loaded_model.load_state_dict(torch.load('./model/link_prediction_{}.pt'.format(i + 1)))\n",
    "    loaded_model.to(device)\n",
    "    pred = predict(\n",
    "        model = loaded_model, \n",
    "        test = test_x\n",
    "    )\n",
    "    # pred.to_csv('./upload/pred_{}.csv'.format(i + 1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf6ea4bd",
   "metadata": {},
   "source": [
    "## Upload File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3b0c3c57-c35b-4b65-83c7-bd3360d6434a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[1 / 50]: 100%|██████████| 136/136 [00:03<00:00, 34.58it/s, loss=tensor(0.5123, device='cuda:0', requires_grad=True)]\n",
      "Epoch[2 / 50]: 100%|██████████| 136/136 [00:04<00:00, 33.71it/s, loss=tensor(0.1410, device='cuda:0', requires_grad=True)]\n",
      "Epoch[3 / 50]: 100%|██████████| 136/136 [00:04<00:00, 33.86it/s, loss=tensor(0.0038, device='cuda:0', requires_grad=True)]  \n",
      "Epoch[4 / 50]: 100%|██████████| 136/136 [00:04<00:00, 32.55it/s, loss=tensor(0.0834, device='cuda:0', requires_grad=True)]  \n",
      "Epoch[5 / 50]: 100%|██████████| 136/136 [00:03<00:00, 34.45it/s, loss=tensor(0.2239, device='cuda:0', requires_grad=True)]\n",
      "Epoch[6 / 50]: 100%|██████████| 136/136 [00:04<00:00, 33.50it/s, loss=tensor(0.0351, device='cuda:0', requires_grad=True)] \n",
      "Epoch[7 / 50]: 100%|██████████| 136/136 [00:04<00:00, 33.89it/s, loss=tensor(0.1833, device='cuda:0', requires_grad=True)]\n",
      "Epoch[8 / 50]: 100%|██████████| 136/136 [00:03<00:00, 35.06it/s, loss=tensor(0.0107, device='cuda:0', requires_grad=True)]   \n",
      "Epoch[9 / 50]: 100%|██████████| 136/136 [00:03<00:00, 35.80it/s, loss=tensor(0.0343, device='cuda:0', requires_grad=True)]   \n",
      "Epoch[10 / 50]: 100%|██████████| 136/136 [00:04<00:00, 28.57it/s, loss=tensor(0.0920, device='cuda:0', requires_grad=True)]\n",
      "Epoch[11 / 50]: 100%|██████████| 136/136 [00:04<00:00, 31.47it/s, loss=tensor(0.0136, device='cuda:0', requires_grad=True)]\n",
      "Epoch[12 / 50]: 100%|██████████| 136/136 [00:03<00:00, 34.86it/s, loss=tensor(0.0367, device='cuda:0', requires_grad=True)]\n",
      "Epoch[13 / 50]: 100%|██████████| 136/136 [00:03<00:00, 35.78it/s, loss=tensor(0.0809, device='cuda:0', requires_grad=True)]\n",
      "Epoch[14 / 50]: 100%|██████████| 136/136 [00:03<00:00, 35.06it/s, loss=tensor(0.0161, device='cuda:0', requires_grad=True)]\n",
      "Epoch[15 / 50]: 100%|██████████| 136/136 [00:04<00:00, 27.40it/s, loss=tensor(0.0177, device='cuda:0', requires_grad=True)] \n",
      "Epoch[16 / 50]: 100%|██████████| 136/136 [00:03<00:00, 34.88it/s, loss=tensor(0.0986, device='cuda:0', requires_grad=True)]\n",
      "Epoch[17 / 50]: 100%|██████████| 136/136 [00:03<00:00, 35.11it/s, loss=tensor(0.0308, device='cuda:0', requires_grad=True)]\n",
      "Epoch[18 / 50]: 100%|██████████| 136/136 [00:03<00:00, 34.37it/s, loss=tensor(0.0104, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[19 / 50]: 100%|██████████| 136/136 [00:03<00:00, 34.13it/s, loss=tensor(0.0903, device='cuda:0', requires_grad=True)]\n",
      "Epoch[20 / 50]: 100%|██████████| 136/136 [00:04<00:00, 29.04it/s, loss=tensor(0.0348, device='cuda:0', requires_grad=True)]\n",
      "Epoch[21 / 50]: 100%|██████████| 136/136 [00:04<00:00, 27.39it/s, loss=tensor(0.0086, device='cuda:0', requires_grad=True)]\n",
      "Epoch[22 / 50]: 100%|██████████| 136/136 [00:04<00:00, 33.55it/s, loss=tensor(0.9256, device='cuda:0', requires_grad=True)]\n",
      "Epoch[23 / 50]: 100%|██████████| 136/136 [00:03<00:00, 35.07it/s, loss=tensor(0.0121, device='cuda:0', requires_grad=True)]   \n",
      "Epoch[24 / 50]: 100%|██████████| 136/136 [00:03<00:00, 35.22it/s, loss=tensor(0.0786, device='cuda:0', requires_grad=True)]\n",
      "Epoch[25 / 50]: 100%|██████████| 136/136 [00:04<00:00, 28.74it/s, loss=tensor(0.0029, device='cuda:0', requires_grad=True)]\n",
      "Epoch[26 / 50]: 100%|██████████| 136/136 [00:04<00:00, 31.61it/s, loss=tensor(0.0077, device='cuda:0', requires_grad=True)]\n",
      "Epoch[27 / 50]: 100%|██████████| 136/136 [00:04<00:00, 28.95it/s, loss=tensor(0.0132, device='cuda:0', requires_grad=True)]\n",
      "Epoch[28 / 50]: 100%|██████████| 136/136 [00:04<00:00, 28.19it/s, loss=tensor(0.0773, device='cuda:0', requires_grad=True)]  \n",
      "Epoch[29 / 50]: 100%|██████████| 136/136 [00:05<00:00, 26.74it/s, loss=tensor(0.2529, device='cuda:0', requires_grad=True)]\n",
      "Epoch[30 / 50]: 100%|██████████| 136/136 [00:04<00:00, 30.02it/s, loss=tensor(0.0664, device='cuda:0', requires_grad=True)]\n",
      "Epoch[31 / 50]: 100%|██████████| 136/136 [00:04<00:00, 27.79it/s, loss=tensor(0.0150, device='cuda:0', requires_grad=True)]\n",
      "Epoch[32 / 50]: 100%|██████████| 136/136 [00:03<00:00, 35.16it/s, loss=tensor(0.0741, device='cuda:0', requires_grad=True)]\n",
      "Epoch[33 / 50]: 100%|██████████| 136/136 [00:04<00:00, 27.95it/s, loss=tensor(0.7177, device='cuda:0', requires_grad=True)]\n",
      "Epoch[34 / 50]: 100%|██████████| 136/136 [00:05<00:00, 26.82it/s, loss=tensor(0.0072, device='cuda:0', requires_grad=True)]   \n",
      "Epoch[35 / 50]: 100%|██████████| 136/136 [00:04<00:00, 30.83it/s, loss=tensor(0.3609, device='cuda:0', requires_grad=True)]\n",
      "Epoch[36 / 50]: 100%|██████████| 136/136 [00:03<00:00, 34.16it/s, loss=tensor(0.0241, device='cuda:0', requires_grad=True)]\n",
      "Epoch[37 / 50]: 100%|██████████| 136/136 [00:04<00:00, 27.70it/s, loss=tensor(0.1842, device='cuda:0', requires_grad=True)]   \n",
      "Epoch[38 / 50]: 100%|██████████| 136/136 [00:03<00:00, 34.34it/s, loss=tensor(0.0767, device='cuda:0', requires_grad=True)] \n",
      "Epoch[39 / 50]: 100%|██████████| 136/136 [00:04<00:00, 27.27it/s, loss=tensor(0.2341, device='cuda:0', requires_grad=True)]\n",
      "Epoch[40 / 50]: 100%|██████████| 136/136 [00:03<00:00, 35.16it/s, loss=tensor(0.6120, device='cuda:0', requires_grad=True)]  \n",
      "Epoch[41 / 50]: 100%|██████████| 136/136 [00:04<00:00, 33.75it/s, loss=tensor(0.1412, device='cuda:0', requires_grad=True)]\n",
      "Epoch[42 / 50]: 100%|██████████| 136/136 [00:04<00:00, 29.19it/s, loss=tensor(0.0797, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[43 / 50]: 100%|██████████| 136/136 [00:04<00:00, 31.07it/s, loss=tensor(0.1151, device='cuda:0', requires_grad=True)]\n",
      "Epoch[44 / 50]: 100%|██████████| 136/136 [00:04<00:00, 28.49it/s, loss=tensor(0.5276, device='cuda:0', requires_grad=True)]\n",
      "Epoch[45 / 50]: 100%|██████████| 136/136 [00:03<00:00, 35.64it/s, loss=tensor(0.1382, device='cuda:0', requires_grad=True)]   \n",
      "Epoch[46 / 50]: 100%|██████████| 136/136 [00:03<00:00, 35.13it/s, loss=tensor(1.1081, device='cuda:0', requires_grad=True)]   \n",
      "Epoch[47 / 50]: 100%|██████████| 136/136 [00:04<00:00, 28.84it/s, loss=tensor(0.0454, device='cuda:0', requires_grad=True)]   \n",
      "Epoch[48 / 50]: 100%|██████████| 136/136 [00:04<00:00, 28.82it/s, loss=tensor(0.3059, device='cuda:0', requires_grad=True)]\n",
      "Epoch[49 / 50]: 100%|██████████| 136/136 [00:05<00:00, 26.79it/s, loss=tensor(0.2604, device='cuda:0', requires_grad=True)]\n",
      "Epoch[50 / 50]: 100%|██████████| 136/136 [00:04<00:00, 27.43it/s, loss=tensor(0.0252, device='cuda:0', requires_grad=True)]\n",
      "Epoch[1 / 50]: 100%|██████████| 118/118 [00:03<00:00, 30.96it/s, loss=tensor(0.1845, device='cuda:0', requires_grad=True)] \n",
      "Epoch[2 / 50]: 100%|██████████| 118/118 [00:04<00:00, 28.28it/s, loss=tensor(11.4515, device='cuda:0', requires_grad=True)]\n",
      "Epoch[3 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.78it/s, loss=tensor(0.1281, device='cuda:0', requires_grad=True)] \n",
      "Epoch[4 / 50]: 100%|██████████| 118/118 [00:04<00:00, 27.51it/s, loss=tensor(0.5773, device='cuda:0', requires_grad=True)] \n",
      "Epoch[5 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.60it/s, loss=tensor(0.2455, device='cuda:0', requires_grad=True)] \n",
      "Epoch[6 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.85it/s, loss=tensor(0.5341, device='cuda:0', requires_grad=True)]  \n",
      "Epoch[7 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.30it/s, loss=tensor(2.3182, device='cuda:0', requires_grad=True)] \n",
      "Epoch[8 / 50]: 100%|██████████| 118/118 [00:03<00:00, 33.24it/s, loss=tensor(0.0903, device='cuda:0', requires_grad=True)] \n",
      "Epoch[9 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.34it/s, loss=tensor(86.2188, device='cuda:0', requires_grad=True)] \n",
      "Epoch[10 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.64it/s, loss=tensor(0.1893, device='cuda:0', requires_grad=True)] \n",
      "Epoch[11 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.25it/s, loss=tensor(2.3077, device='cuda:0', requires_grad=True)]  \n",
      "Epoch[12 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.25it/s, loss=tensor(0.0933, device='cuda:0', requires_grad=True)] \n",
      "Epoch[13 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.37it/s, loss=tensor(1.0244, device='cuda:0', requires_grad=True)]\n",
      "Epoch[14 / 50]: 100%|██████████| 118/118 [00:03<00:00, 35.05it/s, loss=tensor(0.1108, device='cuda:0', requires_grad=True)] \n",
      "Epoch[15 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.85it/s, loss=tensor(135.5680, device='cuda:0', requires_grad=True)]\n",
      "Epoch[16 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.24it/s, loss=tensor(0.7291, device='cuda:0', requires_grad=True)]  \n",
      "Epoch[17 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.65it/s, loss=tensor(0.6004, device='cuda:0', requires_grad=True)] \n",
      "Epoch[18 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.12it/s, loss=tensor(0.3942, device='cuda:0', requires_grad=True)] \n",
      "Epoch[19 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.33it/s, loss=tensor(0.9410, device='cuda:0', requires_grad=True)] \n",
      "Epoch[20 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.55it/s, loss=tensor(0.1444, device='cuda:0', requires_grad=True)] \n",
      "Epoch[21 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.70it/s, loss=tensor(10.7978, device='cuda:0', requires_grad=True)]\n",
      "Epoch[22 / 50]: 100%|██████████| 118/118 [00:04<00:00, 27.80it/s, loss=tensor(0.8698, device='cuda:0', requires_grad=True)] \n",
      "Epoch[23 / 50]: 100%|██████████| 118/118 [00:03<00:00, 30.74it/s, loss=tensor(0.1261, device='cuda:0', requires_grad=True)] \n",
      "Epoch[24 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.76it/s, loss=tensor(0.6351, device='cuda:0', requires_grad=True)] \n",
      "Epoch[25 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.64it/s, loss=tensor(0.0536, device='cuda:0', requires_grad=True)] \n",
      "Epoch[26 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.11it/s, loss=tensor(4.6689, device='cuda:0', requires_grad=True)] \n",
      "Epoch[27 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.58it/s, loss=tensor(3.9041, device='cuda:0', requires_grad=True)]  \n",
      "Epoch[28 / 50]: 100%|██████████| 118/118 [00:04<00:00, 29.29it/s, loss=tensor(0.2335, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[29 / 50]: 100%|██████████| 118/118 [00:03<00:00, 33.73it/s, loss=tensor(0.3209, device='cuda:0', requires_grad=True)]\n",
      "Epoch[30 / 50]: 100%|██████████| 118/118 [00:04<00:00, 29.04it/s, loss=tensor(1.1988, device='cuda:0', requires_grad=True)]  \n",
      "Epoch[31 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.60it/s, loss=tensor(0.3984, device='cuda:0', requires_grad=True)]  \n",
      "Epoch[32 / 50]: 100%|██████████| 118/118 [00:04<00:00, 26.49it/s, loss=tensor(0.7951, device='cuda:0', requires_grad=True)] \n",
      "Epoch[33 / 50]: 100%|██████████| 118/118 [00:04<00:00, 28.22it/s, loss=tensor(0.9334, device='cuda:0', requires_grad=True)] \n",
      "Epoch[34 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.23it/s, loss=tensor(1.0343, device='cuda:0', requires_grad=True)] \n",
      "Epoch[35 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.36it/s, loss=tensor(0.3229, device='cuda:0', requires_grad=True)] \n",
      "Epoch[36 / 50]: 100%|██████████| 118/118 [00:03<00:00, 32.05it/s, loss=tensor(4.0189, device='cuda:0', requires_grad=True)]\n",
      "Epoch[37 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.23it/s, loss=tensor(0.1045, device='cuda:0', requires_grad=True)] \n",
      "Epoch[38 / 50]: 100%|██████████| 118/118 [00:03<00:00, 30.72it/s, loss=tensor(0.6901, device='cuda:0', requires_grad=True)]  \n",
      "Epoch[39 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.13it/s, loss=tensor(1.0932, device='cuda:0', requires_grad=True)]  \n",
      "Epoch[40 / 50]: 100%|██████████| 118/118 [00:04<00:00, 26.72it/s, loss=tensor(0.6769, device='cuda:0', requires_grad=True)] \n",
      "Epoch[41 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.16it/s, loss=tensor(0.7312, device='cuda:0', requires_grad=True)]\n",
      "Epoch[42 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.22it/s, loss=tensor(13.8410, device='cuda:0', requires_grad=True)]\n",
      "Epoch[43 / 50]: 100%|██████████| 118/118 [00:03<00:00, 30.01it/s, loss=tensor(0.0666, device='cuda:0', requires_grad=True)] \n",
      "Epoch[44 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.61it/s, loss=tensor(0.7279, device='cuda:0', requires_grad=True)]  \n",
      "Epoch[45 / 50]: 100%|██████████| 118/118 [00:03<00:00, 30.04it/s, loss=tensor(0.0267, device='cuda:0', requires_grad=True)] \n",
      "Epoch[46 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.72it/s, loss=tensor(2.7186, device='cuda:0', requires_grad=True)] \n",
      "Epoch[47 / 50]: 100%|██████████| 118/118 [00:04<00:00, 28.23it/s, loss=tensor(0.4992, device='cuda:0', requires_grad=True)]  \n",
      "Epoch[48 / 50]: 100%|██████████| 118/118 [00:03<00:00, 34.38it/s, loss=tensor(0.2216, device='cuda:0', requires_grad=True)] \n",
      "Epoch[49 / 50]: 100%|██████████| 118/118 [00:03<00:00, 30.25it/s, loss=tensor(0.0675, device='cuda:0', requires_grad=True)]  \n",
      "Epoch[50 / 50]: 100%|██████████| 118/118 [00:03<00:00, 32.93it/s, loss=tensor(0.3362, device='cuda:0', requires_grad=True)]   \n",
      "Epoch[1 / 50]: 100%|██████████| 41/41 [00:01<00:00, 31.24it/s, loss=tensor(0.0209, device='cuda:0', requires_grad=True)]\n",
      "Epoch[2 / 50]: 100%|██████████| 41/41 [00:01<00:00, 25.38it/s, loss=tensor(0.0129, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[3 / 50]: 100%|██████████| 41/41 [00:01<00:00, 30.88it/s, loss=tensor(0.0826, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[4 / 50]: 100%|██████████| 41/41 [00:01<00:00, 33.97it/s, loss=tensor(0.0412, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[5 / 50]: 100%|██████████| 41/41 [00:01<00:00, 33.51it/s, loss=tensor(0.0726, device='cuda:0', requires_grad=True)]   \n",
      "Epoch[6 / 50]: 100%|██████████| 41/41 [00:01<00:00, 34.19it/s, loss=tensor(0.0478, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[7 / 50]: 100%|██████████| 41/41 [00:01<00:00, 35.34it/s, loss=tensor(0.0874, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[8 / 50]: 100%|██████████| 41/41 [00:01<00:00, 26.46it/s, loss=tensor(0.0390, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[9 / 50]: 100%|██████████| 41/41 [00:01<00:00, 26.41it/s, loss=tensor(0.2215, device='cuda:0', requires_grad=True)]\n",
      "Epoch[10 / 50]: 100%|██████████| 41/41 [00:01<00:00, 32.96it/s, loss=tensor(0.2330, device='cuda:0', requires_grad=True)]\n",
      "Epoch[11 / 50]: 100%|██████████| 41/41 [00:01<00:00, 26.05it/s, loss=tensor(0.0528, device='cuda:0', requires_grad=True)]\n",
      "Epoch[12 / 50]: 100%|██████████| 41/41 [00:01<00:00, 34.17it/s, loss=tensor(0.4972, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[13 / 50]: 100%|██████████| 41/41 [00:01<00:00, 34.40it/s, loss=tensor(0.0236, device='cuda:0', requires_grad=True)]\n",
      "Epoch[14 / 50]: 100%|██████████| 41/41 [00:01<00:00, 33.92it/s, loss=tensor(0.2266, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[15 / 50]: 100%|██████████| 41/41 [00:01<00:00, 26.91it/s, loss=tensor(0.4431, device='cuda:0', requires_grad=True)]\n",
      "Epoch[16 / 50]: 100%|██████████| 41/41 [00:01<00:00, 26.22it/s, loss=tensor(0.0372, device='cuda:0', requires_grad=True)]\n",
      "Epoch[17 / 50]: 100%|██████████| 41/41 [00:01<00:00, 33.80it/s, loss=tensor(0.0135, device='cuda:0', requires_grad=True)]\n",
      "Epoch[18 / 50]: 100%|██████████| 41/41 [00:01<00:00, 34.21it/s, loss=tensor(0.0103, device='cuda:0', requires_grad=True)]\n",
      "Epoch[19 / 50]: 100%|██████████| 41/41 [00:01<00:00, 33.65it/s, loss=tensor(0.0070, device='cuda:0', requires_grad=True)]   \n",
      "Epoch[20 / 50]: 100%|██████████| 41/41 [00:01<00:00, 31.91it/s, loss=tensor(1.6610, device='cuda:0', requires_grad=True)]   \n",
      "Epoch[21 / 50]: 100%|██████████| 41/41 [00:01<00:00, 26.09it/s, loss=tensor(0.0041, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[22 / 50]: 100%|██████████| 41/41 [00:01<00:00, 26.40it/s, loss=tensor(0.0200, device='cuda:0', requires_grad=True)]\n",
      "Epoch[23 / 50]: 100%|██████████| 41/41 [00:01<00:00, 26.40it/s, loss=tensor(0.1938, device='cuda:0', requires_grad=True)]   \n",
      "Epoch[24 / 50]: 100%|██████████| 41/41 [00:01<00:00, 34.59it/s, loss=tensor(0.0822, device='cuda:0', requires_grad=True)]\n",
      "Epoch[25 / 50]: 100%|██████████| 41/41 [00:01<00:00, 34.17it/s, loss=tensor(0.0246, device='cuda:0', requires_grad=True)]\n",
      "Epoch[26 / 50]: 100%|██████████| 41/41 [00:01<00:00, 26.35it/s, loss=tensor(0.0116, device='cuda:0', requires_grad=True)]\n",
      "Epoch[27 / 50]: 100%|██████████| 41/41 [00:01<00:00, 34.23it/s, loss=tensor(0.0842, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[28 / 50]: 100%|██████████| 41/41 [00:01<00:00, 34.11it/s, loss=tensor(0.0162, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[29 / 50]: 100%|██████████| 41/41 [00:01<00:00, 34.33it/s, loss=tensor(0.0065, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[30 / 50]: 100%|██████████| 41/41 [00:01<00:00, 26.02it/s, loss=tensor(0.0028, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[31 / 50]: 100%|██████████| 41/41 [00:01<00:00, 33.93it/s, loss=tensor(0.0562, device='cuda:0', requires_grad=True)]\n",
      "Epoch[32 / 50]: 100%|██████████| 41/41 [00:01<00:00, 34.49it/s, loss=tensor(0.0735, device='cuda:0', requires_grad=True)]\n",
      "Epoch[33 / 50]: 100%|██████████| 41/41 [00:01<00:00, 26.88it/s, loss=tensor(0.1276, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[34 / 50]: 100%|██████████| 41/41 [00:01<00:00, 34.46it/s, loss=tensor(0.0252, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[35 / 50]: 100%|██████████| 41/41 [00:01<00:00, 34.41it/s, loss=tensor(0.0921, device='cuda:0', requires_grad=True)]   \n",
      "Epoch[36 / 50]: 100%|██████████| 41/41 [00:01<00:00, 28.79it/s, loss=tensor(0.0369, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[37 / 50]: 100%|██████████| 41/41 [00:01<00:00, 33.29it/s, loss=tensor(0.0990, device='cuda:0', requires_grad=True)]\n",
      "Epoch[38 / 50]: 100%|██████████| 41/41 [00:01<00:00, 33.73it/s, loss=tensor(0.2099, device='cuda:0', requires_grad=True)]\n",
      "Epoch[39 / 50]: 100%|██████████| 41/41 [00:01<00:00, 26.95it/s, loss=tensor(0.1585, device='cuda:0', requires_grad=True)]\n",
      "Epoch[40 / 50]: 100%|██████████| 41/41 [00:01<00:00, 29.37it/s, loss=tensor(0.3853, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[41 / 50]: 100%|██████████| 41/41 [00:01<00:00, 33.64it/s, loss=tensor(0.0804, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[42 / 50]: 100%|██████████| 41/41 [00:01<00:00, 34.11it/s, loss=tensor(0.6282, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[43 / 50]: 100%|██████████| 41/41 [00:01<00:00, 28.77it/s, loss=tensor(0.0119, device='cuda:0', requires_grad=True)]\n",
      "Epoch[44 / 50]: 100%|██████████| 41/41 [00:01<00:00, 33.89it/s, loss=tensor(0.1565, device='cuda:0', requires_grad=True)]\n",
      "Epoch[45 / 50]: 100%|██████████| 41/41 [00:01<00:00, 26.06it/s, loss=tensor(0.4355, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[46 / 50]: 100%|██████████| 41/41 [00:01<00:00, 31.25it/s, loss=tensor(0.1518, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[47 / 50]: 100%|██████████| 41/41 [00:01<00:00, 27.19it/s, loss=tensor(0.0085, device='cuda:0', requires_grad=True)]   \n",
      "Epoch[48 / 50]: 100%|██████████| 41/41 [00:01<00:00, 33.98it/s, loss=tensor(2.3818, device='cuda:0', requires_grad=True)]\n",
      "Epoch[49 / 50]: 100%|██████████| 41/41 [00:01<00:00, 34.62it/s, loss=tensor(0.0893, device='cuda:0', requires_grad=True)]    \n",
      "Epoch[50 / 50]: 100%|██████████| 41/41 [00:01<00:00, 26.51it/s, loss=tensor(0.0053, device='cuda:0', requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "loss = {}\n",
    "for i in range(3) :\n",
    "    features = new_features[i]\n",
    "    train_x = train[i]\n",
    "    test_x = test[i]\n",
    "    model = link_predict(features.to(device)).to(device)\n",
    "    n_epochs = 50\n",
    "    batch_size = 64\n",
    "    ls_loss = save(\n",
    "        features = features, \n",
    "        train = train_x, \n",
    "        n_epochs = n_epochs, \n",
    "        batch_size = batch_size, \n",
    "        sigma = 100\n",
    "    )\n",
    "    fig = plt.figure()\n",
    "    plt.title('Loss_{}'.format(i))\n",
    "    temp = np.array(ls_loss)\n",
    "    plt.plot(range(1, n_epochs + 1), ls_loss)\n",
    "    plt.savefig('./figure/loss_{}.png'.format(i + 1))\n",
    "    plt.close(fig)\n",
    "    loss[i] = ls_loss\n",
    "    filename = './model/link_prediction_{}.pt'.format(i + 1)\n",
    "    torch.save(model.state_dict(), filename)\n",
    "\n",
    "with open(\"loss.txt\", \"w\") as fp:\n",
    "    json.dump(loss, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "40e666cf-f557-46ac-9dd8-b3d6471a847b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, test) :\n",
    "    test_x = torch.Tensor(np.array(test.iloc[::, 1:])).to(device)\n",
    "    test_y = loaded_model(test_x)\n",
    "    test_y = pd.DataFrame(test_y)\n",
    "    pred = pd.concat([test, test_y], axis = 1)\n",
    "    pred = pred.drop(['to', 'from'], axis = 1)\n",
    "    pred.columns = ['id', 'prob']\n",
    "    return pred\n",
    "for i in range(3) :\n",
    "    features = new_features[i]\n",
    "    test_x = test[i]\n",
    "    loaded_model = link_predict(features.to(device)).to(device)\n",
    "    loaded_model.load_state_dict(torch.load('./model/link_prediction_{}.pt'.format(i + 1)))\n",
    "    loaded_model.to(device)\n",
    "    pred = predict(\n",
    "        model = loaded_model, \n",
    "        test = test_x\n",
    "    )\n",
    "    pred.to_csv('./upload/pred_{}.csv'.format(i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515fa9fd-b13f-43c9-a447-9341e19711d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterlab",
   "language": "python",
   "name": "jupyterlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
