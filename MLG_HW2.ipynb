{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7bfe866-5253-46c1-909a-b312289edf07",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MLG HW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a50480a-8387-4943-99b7-53f156fa6e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, time, torch, json\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# from torch_geometric.utils import accuracy,sparse_mx_to_torch_sparse_tensor\n",
    "import torch_geometric.utils \n",
    "# from models.GCN import GCN\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm, trange\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data as Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "709c4b57-737c-4780-a5f6-fbc684fb92e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "       id    to  from\n",
      "0  E10559  2323  2673\n",
      "1   E4849    81  1634\n",
      "       id    to  from  label\n",
      "0  E10311  2399  2339      0\n",
      "1  E10255  2397  1144      1\n",
      "     to  from\n",
      "0  2397  1144\n",
      "1  2450  1312\n",
      "       id  prob\n",
      "0  E10559   0.5\n",
      "1   E4849   0.5\n"
     ]
    }
   ],
   "source": [
    "content = []\n",
    "test = []\n",
    "train = []\n",
    "upload = []\n",
    "edge_index = [] \n",
    "for i in range(3):\n",
    "    os.chdir('/home/rita/111/111-2MLG/HW2/dataset{}'.format(i + 1))\n",
    "    temp = pd.read_csv('./content.csv', header = None, sep = '\\t')\n",
    "    temp.sort_values(by = [0], inplace = True)\n",
    "    temp.set_index([0], inplace = True)\n",
    "    temp = torch.Tensor(np.array(temp)).to(torch.float32)\n",
    "    content.append(temp)\n",
    "    test.append(pd.read_csv('./test.csv'))\n",
    "    temp = pd.read_csv('./train.csv')\n",
    "    train.append(temp)\n",
    "    temp = temp[temp.label == 1]\n",
    "    temp = temp[['to', 'from']]\n",
    "    temp = temp.reset_index(drop = True)\n",
    "    edge_index.append(temp)\n",
    "    upload.append(pd.read_csv('./upload.csv'))\n",
    "print(content[0][:2])\n",
    "print(test[0].head(2))\n",
    "print(train[0].head(2))\n",
    "print(edge_index[0].head(2))\n",
    "print(upload[0].head(2))\n",
    "os.chdir('/home/rita/111/111-2MLG/HW2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce7cd1c5-5478-4bd9-a400-d22f767ace87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class link_predict(nn.Module) :\n",
    "    def __init__(self, features, emb_dim = 128) :\n",
    "        super(link_predict, self).__init__()\n",
    "        self.features = features\n",
    "        self.edge_index = edge_index\n",
    "        self.emb_dim = emb_dim\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(self.features.shape[1], self.emb_dim), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(self.emb_dim, self.emb_dim)\n",
    "        )\n",
    "        # self.poten_edges = self.get_poten_edges(fearures)\n",
    "        \n",
    "    def forward(self, want_edge) :\n",
    "        z = self.mlp(self.features)\n",
    "        out = []\n",
    "        for i in range(want_edge.shape[0]) :\n",
    "            idx1 = want_edge[i, 0].type(torch.LongTensor)\n",
    "            idx2 = want_edge[i, 1].type(torch.LongTensor)\n",
    "            temp = (z[idx1] * z[idx2]).sum()\n",
    "            # temp = torch.matmul(z[idx1], z[idx2].T)\n",
    "            temp = temp if temp > 0 else 0\n",
    "            out.append(temp)\n",
    "        return torch.tensor(out).reshape(-1, 1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20d78c7e-c0dc-48a0-9097-9b8a43d8fd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\") #可以根據輸出結果知道是否有可用的GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4bc8f49-2796-4aaf-803f-03ab492cc29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[1 / 5]: 100%|██████████| 136/136 [00:03<00:00, 37.94it/s, loss=tensor(11.6618, device='cuda:0', requires_grad=True)]\n",
      "Epoch[2 / 5]: 100%|██████████| 136/136 [00:03<00:00, 38.28it/s, loss=tensor(10.8918, device='cuda:0', requires_grad=True)]\n",
      "Epoch[3 / 5]: 100%|██████████| 136/136 [00:03<00:00, 35.28it/s, loss=tensor(10.8402, device='cuda:0', requires_grad=True)]\n",
      "Epoch[4 / 5]: 100%|██████████| 136/136 [00:03<00:00, 39.16it/s, loss=tensor(12.2047, device='cuda:0', requires_grad=True)]\n",
      "Epoch[5 / 5]: 100%|██████████| 136/136 [00:03<00:00, 38.51it/s, loss=tensor(12.9162, device='cuda:0', requires_grad=True)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.0305073261261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def training_loop(model, n_epochs, optimizer, loss_fn, features, train_loader, sigma, val_loader = None) :\n",
    "    ls_train_loss = []\n",
    "    ls_val_loss = []\n",
    "    features = features.to(torch.float32).to(device = device)\n",
    "    for epoch in range(1, n_epochs + 1) :  \n",
    "        val_loss = 0\n",
    "        loop = tqdm(enumerate(train_loader), total = len(train_loader))\n",
    "        for i, (edge, labels) in loop :\n",
    "            poten = get_poten_edges(features, edge)\n",
    "            edge = edge.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(edge).to(device)            \n",
    "            loss = 0\n",
    "            for j in range(labels.shape[0]) :\n",
    "                if(labels[j] == 1):\n",
    "                    loss += torch.exp(-(poten[j]/sigma**2)) * loss_fn(outputs[j], labels[j])\n",
    "                else :\n",
    "                    loss += torch.exp((poten[j]/sigma**2)) * loss_fn(outputs[j], labels[j])         \n",
    "            loss.requires_grad_()\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "            loop.set_description(f'Epoch[{epoch} / {n_epochs}]')\n",
    "            # if (i+1 == len(train_loader)) :\n",
    "            #     val_loss = validate(model, loss_fn, val_loader)\n",
    "            # loop.set_postfix(loss = loss, val_loss = val_loss)\n",
    "            loop.set_postfix(loss = loss)\n",
    "        ls_train_loss.append(loss.item()) \n",
    "    \n",
    "    return ls_train_loss\n",
    "        \n",
    "def get_poten_edges(features, edge) :\n",
    "    poten_edges = []\n",
    "    for i in range(edge.shape[0]) :\n",
    "        idx1 = edge[i, 0].type(torch.LongTensor)\n",
    "        idx2 = edge[i, 1].type(torch.LongTensor)\n",
    "        temp = (features[idx1] == features[idx2]).sum() \n",
    "        poten_edges.append(temp)\n",
    "    temp -=temp.min()        \n",
    "    return torch.tensor(poten_edges)    \n",
    "\n",
    "def validate(model, loss_fn, loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss = 0\n",
    "    with torch.no_grad(): \n",
    "        for edges, labels in loader:\n",
    "            poten = get_poten_edges(features, edges)\n",
    "            edges = edges.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(edges).to(device)  \n",
    "            total += labels.shape[0] \n",
    "            for i in range(labels.shape[0]) :\n",
    "                if(labels[i] == 1):\n",
    "                    loss += torch.exp(-(poten[i]/sigma**2)) * loss_fn(outputs[i], labels[i])\n",
    "                else :\n",
    "                    loss += torch.exp((poten[i]/sigma**2)) * loss_fn(outputs[i], labels[i])     \n",
    "    loss /= total       \n",
    "   \n",
    "    return loss\n",
    "    \n",
    "s = time.time()\n",
    "model = link_predict(content[0].to(device)).to(device)\n",
    "# L2 regularization\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay = 1e-5)  \n",
    "loss_fn = nn.MSELoss()\n",
    "n_epochs = 5\n",
    "features = content[0]\n",
    "train_x = train[0]\n",
    "train_y = torch.Tensor(np.array(train_x.iloc[::, -1])).to(torch.float32)\n",
    "train_x = torch.Tensor(np.array(train_x.iloc[::, [1, 2]])).to(torch.float32)\n",
    "# train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.33, random_state=42)\n",
    "train_dataset = Data.TensorDataset(train_x, train_y)\n",
    "# val_dataset = Data.TensorDataset(val_x, val_y)\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = 4\n",
    ")\n",
    "# val_loader = DataLoader(\n",
    "#     dataset = val_dataset,\n",
    "#     batch_size = batch_size,\n",
    "#     shuffle = True,\n",
    "#     num_workers = 4\n",
    "# )\n",
    "sigma = 100\n",
    "\n",
    "ls_loss = training_loop( \n",
    "    model = model, \n",
    "    n_epochs = n_epochs,\n",
    "    optimizer = optimizer,\n",
    "    loss_fn = loss_fn,\n",
    "    features = features, \n",
    "    train_loader = train_loader, \n",
    "    val_loader = val_loader, \n",
    "    sigma = sigma\n",
    ")\n",
    "print(time.time() - s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615a4771-d3ab-4e48-a207-8e105b157e61",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b0c3c57-c35b-4b65-83c7-bd3360d6434a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[1 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.03it/s, loss=tensor(11.6286, device='cuda:0', requires_grad=True)]\n",
      "Epoch[2 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.34it/s, loss=tensor(11.5539, device='cuda:0', requires_grad=True)]\n",
      "Epoch[3 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.67it/s, loss=tensor(11.8685, device='cuda:0', requires_grad=True)]\n",
      "Epoch[4 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.34it/s, loss=tensor(10.9414, device='cuda:0', requires_grad=True)]\n",
      "Epoch[5 / 50]: 100%|██████████| 136/136 [00:03<00:00, 35.57it/s, loss=tensor(11.6622, device='cuda:0', requires_grad=True)]\n",
      "Epoch[6 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.65it/s, loss=tensor(11.2373, device='cuda:0', requires_grad=True)]\n",
      "Epoch[7 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.15it/s, loss=tensor(11.6222, device='cuda:0', requires_grad=True)]\n",
      "Epoch[8 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.44it/s, loss=tensor(10.5314, device='cuda:0', requires_grad=True)]\n",
      "Epoch[9 / 50]: 100%|██████████| 136/136 [00:03<00:00, 37.41it/s, loss=tensor(10.9736, device='cuda:0', requires_grad=True)]\n",
      "Epoch[10 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.52it/s, loss=tensor(11.6232, device='cuda:0', requires_grad=True)]\n",
      "Epoch[11 / 50]: 100%|██████████| 136/136 [00:03<00:00, 37.99it/s, loss=tensor(11.9236, device='cuda:0', requires_grad=True)]\n",
      "Epoch[12 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.25it/s, loss=tensor(11.1043, device='cuda:0', requires_grad=True)]\n",
      "Epoch[13 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.27it/s, loss=tensor(11.2931, device='cuda:0', requires_grad=True)]\n",
      "Epoch[14 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.60it/s, loss=tensor(11.9591, device='cuda:0', requires_grad=True)]\n",
      "Epoch[15 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.40it/s, loss=tensor(12.0023, device='cuda:0', requires_grad=True)]\n",
      "Epoch[16 / 50]: 100%|██████████| 136/136 [00:03<00:00, 39.33it/s, loss=tensor(11.4232, device='cuda:0', requires_grad=True)]\n",
      "Epoch[17 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.32it/s, loss=tensor(11.4345, device='cuda:0', requires_grad=True)]\n",
      "Epoch[18 / 50]: 100%|██████████| 136/136 [00:03<00:00, 39.74it/s, loss=tensor(11.9292, device='cuda:0', requires_grad=True)]\n",
      "Epoch[19 / 50]: 100%|██████████| 136/136 [00:03<00:00, 37.99it/s, loss=tensor(12.6051, device='cuda:0', requires_grad=True)]\n",
      "Epoch[20 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.78it/s, loss=tensor(11.2729, device='cuda:0', requires_grad=True)]\n",
      "Epoch[21 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.14it/s, loss=tensor(11.4439, device='cuda:0', requires_grad=True)]\n",
      "Epoch[22 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.62it/s, loss=tensor(11.1751, device='cuda:0', requires_grad=True)]\n",
      "Epoch[23 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.31it/s, loss=tensor(10.9212, device='cuda:0', requires_grad=True)]\n",
      "Epoch[24 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.46it/s, loss=tensor(11.4034, device='cuda:0', requires_grad=True)]\n",
      "Epoch[25 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.46it/s, loss=tensor(11.9373, device='cuda:0', requires_grad=True)]\n",
      "Epoch[26 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.29it/s, loss=tensor(11.8624, device='cuda:0', requires_grad=True)]\n",
      "Epoch[27 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.87it/s, loss=tensor(11.4788, device='cuda:0', requires_grad=True)]\n",
      "Epoch[28 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.01it/s, loss=tensor(11.1140, device='cuda:0', requires_grad=True)]\n",
      "Epoch[29 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.14it/s, loss=tensor(11.3466, device='cuda:0', requires_grad=True)]\n",
      "Epoch[30 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.07it/s, loss=tensor(11.6157, device='cuda:0', requires_grad=True)]\n",
      "Epoch[31 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.74it/s, loss=tensor(11.5138, device='cuda:0', requires_grad=True)]\n",
      "Epoch[32 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.34it/s, loss=tensor(11.5107, device='cuda:0', requires_grad=True)]\n",
      "Epoch[33 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.78it/s, loss=tensor(10.8842, device='cuda:0', requires_grad=True)]\n",
      "Epoch[34 / 50]: 100%|██████████| 136/136 [00:03<00:00, 39.17it/s, loss=tensor(11.4437, device='cuda:0', requires_grad=True)]\n",
      "Epoch[35 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.63it/s, loss=tensor(10.8972, device='cuda:0', requires_grad=True)]\n",
      "Epoch[36 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.49it/s, loss=tensor(11.2454, device='cuda:0', requires_grad=True)]\n",
      "Epoch[37 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.17it/s, loss=tensor(12.0997, device='cuda:0', requires_grad=True)]\n",
      "Epoch[38 / 50]: 100%|██████████| 136/136 [00:03<00:00, 39.07it/s, loss=tensor(10.6916, device='cuda:0', requires_grad=True)]\n",
      "Epoch[39 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.32it/s, loss=tensor(11.8525, device='cuda:0', requires_grad=True)]\n",
      "Epoch[40 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.42it/s, loss=tensor(11.2152, device='cuda:0', requires_grad=True)]\n",
      "Epoch[41 / 50]: 100%|██████████| 136/136 [00:03<00:00, 39.19it/s, loss=tensor(11.3266, device='cuda:0', requires_grad=True)]\n",
      "Epoch[42 / 50]: 100%|██████████| 136/136 [00:03<00:00, 37.83it/s, loss=tensor(12.0476, device='cuda:0', requires_grad=True)]\n",
      "Epoch[43 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.25it/s, loss=tensor(11.1795, device='cuda:0', requires_grad=True)]\n",
      "Epoch[44 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.05it/s, loss=tensor(11.0955, device='cuda:0', requires_grad=True)]\n",
      "Epoch[45 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.47it/s, loss=tensor(12.0151, device='cuda:0', requires_grad=True)]\n",
      "Epoch[46 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.66it/s, loss=tensor(11.1718, device='cuda:0', requires_grad=True)]\n",
      "Epoch[47 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.33it/s, loss=tensor(11.4445, device='cuda:0', requires_grad=True)]\n",
      "Epoch[48 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.13it/s, loss=tensor(10.7476, device='cuda:0', requires_grad=True)]\n",
      "Epoch[49 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.23it/s, loss=tensor(11.1143, device='cuda:0', requires_grad=True)]\n",
      "Epoch[50 / 50]: 100%|██████████| 136/136 [00:03<00:00, 38.73it/s, loss=tensor(10.9684, device='cuda:0', requires_grad=True)]\n",
      "Epoch[1 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.02it/s, loss=tensor(13.5058, device='cuda:0', requires_grad=True)]\n",
      "Epoch[2 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.35it/s, loss=tensor(12.0550, device='cuda:0', requires_grad=True)]\n",
      "Epoch[3 / 50]: 100%|██████████| 118/118 [00:03<00:00, 37.97it/s, loss=tensor(13.4364, device='cuda:0', requires_grad=True)]\n",
      "Epoch[4 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.16it/s, loss=tensor(13.3223, device='cuda:0', requires_grad=True)]\n",
      "Epoch[5 / 50]: 100%|██████████| 118/118 [00:03<00:00, 37.76it/s, loss=tensor(13.0115, device='cuda:0', requires_grad=True)]\n",
      "Epoch[6 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.46it/s, loss=tensor(12.0920, device='cuda:0', requires_grad=True)]\n",
      "Epoch[7 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.16it/s, loss=tensor(12.1115, device='cuda:0', requires_grad=True)]\n",
      "Epoch[8 / 50]: 100%|██████████| 118/118 [00:03<00:00, 37.98it/s, loss=tensor(12.0421, device='cuda:0', requires_grad=True)]\n",
      "Epoch[9 / 50]: 100%|██████████| 118/118 [00:03<00:00, 37.45it/s, loss=tensor(12.9530, device='cuda:0', requires_grad=True)]\n",
      "Epoch[10 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.05it/s, loss=tensor(13.5665, device='cuda:0', requires_grad=True)]\n",
      "Epoch[11 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.49it/s, loss=tensor(13.8721, device='cuda:0', requires_grad=True)]\n",
      "Epoch[12 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.07it/s, loss=tensor(13.4699, device='cuda:0', requires_grad=True)]\n",
      "Epoch[13 / 50]: 100%|██████████| 118/118 [00:03<00:00, 37.69it/s, loss=tensor(13.2042, device='cuda:0', requires_grad=True)]\n",
      "Epoch[14 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.12it/s, loss=tensor(12.5246, device='cuda:0', requires_grad=True)]\n",
      "Epoch[15 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.24it/s, loss=tensor(13.3132, device='cuda:0', requires_grad=True)]\n",
      "Epoch[16 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.66it/s, loss=tensor(13.1948, device='cuda:0', requires_grad=True)]\n",
      "Epoch[17 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.41it/s, loss=tensor(11.7311, device='cuda:0', requires_grad=True)]\n",
      "Epoch[18 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.43it/s, loss=tensor(14.3878, device='cuda:0', requires_grad=True)]\n",
      "Epoch[19 / 50]: 100%|██████████| 118/118 [00:03<00:00, 37.74it/s, loss=tensor(14.3892, device='cuda:0', requires_grad=True)]\n",
      "Epoch[20 / 50]: 100%|██████████| 118/118 [00:03<00:00, 37.58it/s, loss=tensor(12.4942, device='cuda:0', requires_grad=True)]\n",
      "Epoch[21 / 50]: 100%|██████████| 118/118 [00:03<00:00, 37.93it/s, loss=tensor(13.3679, device='cuda:0', requires_grad=True)]\n",
      "Epoch[22 / 50]: 100%|██████████| 118/118 [00:03<00:00, 37.76it/s, loss=tensor(12.0234, device='cuda:0', requires_grad=True)]\n",
      "Epoch[23 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.11it/s, loss=tensor(11.3682, device='cuda:0', requires_grad=True)]\n",
      "Epoch[24 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.22it/s, loss=tensor(13.6501, device='cuda:0', requires_grad=True)]\n",
      "Epoch[25 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.61it/s, loss=tensor(13.5213, device='cuda:0', requires_grad=True)]\n",
      "Epoch[26 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.27it/s, loss=tensor(14.0106, device='cuda:0', requires_grad=True)]\n",
      "Epoch[27 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.09it/s, loss=tensor(11.8052, device='cuda:0', requires_grad=True)]\n",
      "Epoch[28 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.71it/s, loss=tensor(12.0314, device='cuda:0', requires_grad=True)]\n",
      "Epoch[29 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.56it/s, loss=tensor(12.7709, device='cuda:0', requires_grad=True)]\n",
      "Epoch[30 / 50]: 100%|██████████| 118/118 [00:03<00:00, 37.98it/s, loss=tensor(11.6977, device='cuda:0', requires_grad=True)]\n",
      "Epoch[31 / 50]: 100%|██████████| 118/118 [00:03<00:00, 39.26it/s, loss=tensor(12.9656, device='cuda:0', requires_grad=True)]\n",
      "Epoch[32 / 50]: 100%|██████████| 118/118 [00:03<00:00, 37.68it/s, loss=tensor(13.2028, device='cuda:0', requires_grad=True)]\n",
      "Epoch[33 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.16it/s, loss=tensor(12.8812, device='cuda:0', requires_grad=True)]\n",
      "Epoch[34 / 50]: 100%|██████████| 118/118 [00:03<00:00, 37.97it/s, loss=tensor(12.3388, device='cuda:0', requires_grad=True)]\n",
      "Epoch[35 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.20it/s, loss=tensor(12.1458, device='cuda:0', requires_grad=True)]\n",
      "Epoch[36 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.45it/s, loss=tensor(13.5520, device='cuda:0', requires_grad=True)]\n",
      "Epoch[37 / 50]: 100%|██████████| 118/118 [00:03<00:00, 37.53it/s, loss=tensor(12.0666, device='cuda:0', requires_grad=True)]\n",
      "Epoch[38 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.25it/s, loss=tensor(13.6004, device='cuda:0', requires_grad=True)]\n",
      "Epoch[39 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.57it/s, loss=tensor(12.6593, device='cuda:0', requires_grad=True)]\n",
      "Epoch[40 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.16it/s, loss=tensor(13.7705, device='cuda:0', requires_grad=True)]\n",
      "Epoch[41 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.13it/s, loss=tensor(11.8039, device='cuda:0', requires_grad=True)]\n",
      "Epoch[42 / 50]: 100%|██████████| 118/118 [00:03<00:00, 37.94it/s, loss=tensor(13.0428, device='cuda:0', requires_grad=True)]\n",
      "Epoch[43 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.32it/s, loss=tensor(12.9552, device='cuda:0', requires_grad=True)]\n",
      "Epoch[44 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.12it/s, loss=tensor(12.7981, device='cuda:0', requires_grad=True)]\n",
      "Epoch[45 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.21it/s, loss=tensor(13.0562, device='cuda:0', requires_grad=True)]\n",
      "Epoch[46 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.09it/s, loss=tensor(11.3098, device='cuda:0', requires_grad=True)]\n",
      "Epoch[47 / 50]: 100%|██████████| 118/118 [00:03<00:00, 37.90it/s, loss=tensor(12.2657, device='cuda:0', requires_grad=True)]\n",
      "Epoch[48 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.03it/s, loss=tensor(13.5571, device='cuda:0', requires_grad=True)]\n",
      "Epoch[49 / 50]: 100%|██████████| 118/118 [00:03<00:00, 37.72it/s, loss=tensor(12.6441, device='cuda:0', requires_grad=True)]\n",
      "Epoch[50 / 50]: 100%|██████████| 118/118 [00:03<00:00, 38.96it/s, loss=tensor(11.7697, device='cuda:0', requires_grad=True)]\n",
      "Epoch[1 / 50]: 100%|██████████| 41/41 [00:01<00:00, 37.26it/s, loss=tensor(2.3844, device='cuda:0', requires_grad=True)] \n",
      "Epoch[2 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.54it/s, loss=tensor(2.5915, device='cuda:0', requires_grad=True)] \n",
      "Epoch[3 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.22it/s, loss=tensor(3.0207, device='cuda:0', requires_grad=True)] \n",
      "Epoch[4 / 50]: 100%|██████████| 41/41 [00:01<00:00, 37.74it/s, loss=tensor(2.8083, device='cuda:0', requires_grad=True)] \n",
      "Epoch[5 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.97it/s, loss=tensor(2.9996, device='cuda:0', requires_grad=True)] \n",
      "Epoch[6 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.04it/s, loss=tensor(2.7743, device='cuda:0', requires_grad=True)] \n",
      "Epoch[7 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.86it/s, loss=tensor(2.7503, device='cuda:0', requires_grad=True)] \n",
      "Epoch[8 / 50]: 100%|██████████| 41/41 [00:01<00:00, 37.16it/s, loss=tensor(2.8359, device='cuda:0', requires_grad=True)] \n",
      "Epoch[9 / 50]: 100%|██████████| 41/41 [00:01<00:00, 37.64it/s, loss=tensor(2.6510, device='cuda:0', requires_grad=True)] \n",
      "Epoch[10 / 50]: 100%|██████████| 41/41 [00:01<00:00, 37.31it/s, loss=tensor(2.9109, device='cuda:0', requires_grad=True)] \n",
      "Epoch[11 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.18it/s, loss=tensor(2.3872, device='cuda:0', requires_grad=True)] \n",
      "Epoch[12 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.90it/s, loss=tensor(2.8479, device='cuda:0', requires_grad=True)] \n",
      "Epoch[13 / 50]: 100%|██████████| 41/41 [00:01<00:00, 37.27it/s, loss=tensor(2.8264, device='cuda:0', requires_grad=True)] \n",
      "Epoch[14 / 50]: 100%|██████████| 41/41 [00:01<00:00, 37.40it/s, loss=tensor(2.8410, device='cuda:0', requires_grad=True)] \n",
      "Epoch[15 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.37it/s, loss=tensor(2.8243, device='cuda:0', requires_grad=True)] \n",
      "Epoch[16 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.81it/s, loss=tensor(2.9676, device='cuda:0', requires_grad=True)] \n",
      "Epoch[17 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.82it/s, loss=tensor(2.8513, device='cuda:0', requires_grad=True)] \n",
      "Epoch[18 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.51it/s, loss=tensor(2.5323, device='cuda:0', requires_grad=True)] \n",
      "Epoch[19 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.91it/s, loss=tensor(2.8365, device='cuda:0', requires_grad=True)] \n",
      "Epoch[20 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.38it/s, loss=tensor(2.5702, device='cuda:0', requires_grad=True)] \n",
      "Epoch[21 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.86it/s, loss=tensor(2.9568, device='cuda:0', requires_grad=True)] \n",
      "Epoch[22 / 50]: 100%|██████████| 41/41 [00:01<00:00, 34.99it/s, loss=tensor(2.6030, device='cuda:0', requires_grad=True)] \n",
      "Epoch[23 / 50]: 100%|██████████| 41/41 [00:01<00:00, 37.26it/s, loss=tensor(2.7169, device='cuda:0', requires_grad=True)] \n",
      "Epoch[24 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.18it/s, loss=tensor(2.9210, device='cuda:0', requires_grad=True)] \n",
      "Epoch[25 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.06it/s, loss=tensor(2.7767, device='cuda:0', requires_grad=True)] \n",
      "Epoch[26 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.31it/s, loss=tensor(3.0564, device='cuda:0', requires_grad=True)] \n",
      "Epoch[27 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.23it/s, loss=tensor(2.7672, device='cuda:0', requires_grad=True)] \n",
      "Epoch[28 / 50]: 100%|██████████| 41/41 [00:01<00:00, 37.85it/s, loss=tensor(2.8944, device='cuda:0', requires_grad=True)] \n",
      "Epoch[29 / 50]: 100%|██████████| 41/41 [00:01<00:00, 37.19it/s, loss=tensor(2.5021, device='cuda:0', requires_grad=True)] \n",
      "Epoch[30 / 50]: 100%|██████████| 41/41 [00:01<00:00, 37.27it/s, loss=tensor(2.2459, device='cuda:0', requires_grad=True)] \n",
      "Epoch[31 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.03it/s, loss=tensor(2.9117, device='cuda:0', requires_grad=True)] \n",
      "Epoch[32 / 50]: 100%|██████████| 41/41 [00:01<00:00, 34.40it/s, loss=tensor(2.4569, device='cuda:0', requires_grad=True)] \n",
      "Epoch[33 / 50]: 100%|██████████| 41/41 [00:01<00:00, 37.32it/s, loss=tensor(2.8275, device='cuda:0', requires_grad=True)] \n",
      "Epoch[34 / 50]: 100%|██████████| 41/41 [00:01<00:00, 35.84it/s, loss=tensor(3.1384, device='cuda:0', requires_grad=True)] \n",
      "Epoch[35 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.87it/s, loss=tensor(2.9876, device='cuda:0', requires_grad=True)] \n",
      "Epoch[36 / 50]: 100%|██████████| 41/41 [00:01<00:00, 35.84it/s, loss=tensor(2.3871, device='cuda:0', requires_grad=True)] \n",
      "Epoch[37 / 50]: 100%|██████████| 41/41 [00:01<00:00, 37.50it/s, loss=tensor(3.6789, device='cuda:0', requires_grad=True)] \n",
      "Epoch[38 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.19it/s, loss=tensor(2.8698, device='cuda:0', requires_grad=True)] \n",
      "Epoch[39 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.86it/s, loss=tensor(3.1584, device='cuda:0', requires_grad=True)] \n",
      "Epoch[40 / 50]: 100%|██████████| 41/41 [00:01<00:00, 37.37it/s, loss=tensor(3.1844, device='cuda:0', requires_grad=True)] \n",
      "Epoch[41 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.94it/s, loss=tensor(2.6569, device='cuda:0', requires_grad=True)] \n",
      "Epoch[42 / 50]: 100%|██████████| 41/41 [00:01<00:00, 35.85it/s, loss=tensor(3.1478, device='cuda:0', requires_grad=True)] \n",
      "Epoch[43 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.40it/s, loss=tensor(2.4050, device='cuda:0', requires_grad=True)] \n",
      "Epoch[44 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.57it/s, loss=tensor(2.9356, device='cuda:0', requires_grad=True)] \n",
      "Epoch[45 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.35it/s, loss=tensor(2.5697, device='cuda:0', requires_grad=True)] \n",
      "Epoch[46 / 50]: 100%|██████████| 41/41 [00:01<00:00, 35.91it/s, loss=tensor(3.2499, device='cuda:0', requires_grad=True)] \n",
      "Epoch[47 / 50]: 100%|██████████| 41/41 [00:01<00:00, 36.58it/s, loss=tensor(3.1740, device='cuda:0', requires_grad=True)] \n",
      "Epoch[48 / 50]: 100%|██████████| 41/41 [00:01<00:00, 37.28it/s, loss=tensor(2.6349, device='cuda:0', requires_grad=True)] \n",
      "Epoch[49 / 50]: 100%|██████████| 41/41 [00:01<00:00, 35.56it/s, loss=tensor(2.6734, device='cuda:0', requires_grad=True)] \n",
      "Epoch[50 / 50]: 100%|██████████| 41/41 [00:01<00:00, 37.10it/s, loss=tensor(2.8152, device='cuda:0', requires_grad=True)] \n"
     ]
    }
   ],
   "source": [
    "def save(features, train, n_epochs = 100, batch_size = 64, sigma = 100) :\n",
    "    model = link_predict(features.to(device)).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay = 1e-5)  \n",
    "    loss_fn = nn.MSELoss()\n",
    "    train_y = torch.Tensor(np.array(train.iloc[::, -1])).to(torch.float32)\n",
    "    train_x = torch.Tensor(np.array(train.iloc[::, [1, 2]])).to(torch.float32)\n",
    "    # train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.33, random_state=42)\n",
    "    train_dataset = Data.TensorDataset(train_x, train_y)\n",
    "    # val_dataset = Data.TensorDataset(val_x, val_y)\n",
    "    train_loader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True,\n",
    "        num_workers = 4\n",
    "    )\n",
    "    # val_loader = DataLoader(\n",
    "    #     dataset = val_dataset,\n",
    "    #     batch_size = batch_size,\n",
    "    #     shuffle = True,\n",
    "    #     num_workers = 4\n",
    "    # )\n",
    "    ls_loss = training_loop( \n",
    "        model = model, \n",
    "        n_epochs = n_epochs,\n",
    "        optimizer = optimizer,\n",
    "        loss_fn = loss_fn,\n",
    "        features = features, \n",
    "        train_loader = train_loader, \n",
    "        val_loader = val_loader, \n",
    "        sigma = sigma\n",
    "    )\n",
    "    return ls_loss\n",
    "\n",
    "loss = {}\n",
    "for i in range(3) :\n",
    "    features = content[i]\n",
    "    train_x = train[i]\n",
    "    test_x = test[i]\n",
    "    model = link_predict(features.to(device)).to(device)\n",
    "    n_epochs = 50\n",
    "    batch_size = 64\n",
    "    ls_loss = save(\n",
    "        features = features, \n",
    "        train = train_x, \n",
    "        n_epochs = n_epochs, \n",
    "        batch_size = batch_size, \n",
    "        sigma = 100\n",
    "    )\n",
    "    fig = plt.figure()\n",
    "    plt.title('Loss_{}'.format(i))\n",
    "    temp = np.array(ls_loss)\n",
    "    plt.plot(range(1, n_epochs + 1), ls_loss)\n",
    "    plt.savefig('./figure/loss_{}.png'.format(i + 1))\n",
    "    plt.close(fig)\n",
    "    loss[i] = ls_loss\n",
    "    filename = './model/link_prediction_{}.pt'.format(i + 1)\n",
    "    torch.save(model.state_dict(), filename)\n",
    "\n",
    "with open(\"loss.txt\", \"w\") as fp:\n",
    "    json.dump(loss, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "40e666cf-f557-46ac-9dd8-b3d6471a847b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, test) :\n",
    "    test_x = torch.Tensor(np.array(test.iloc[::, 1:])).to(device)\n",
    "    test_y = loaded_model(test_x)\n",
    "    test_y = pd.DataFrame(test_y)\n",
    "    pred = pd.concat([test, test_y], axis = 1)\n",
    "    pred = pred.drop(['to', 'from'], axis = 1)\n",
    "    pred.columns = ['id', 'prob']\n",
    "    return pred\n",
    "for i in range(3) :\n",
    "    features = content[i]\n",
    "    test_x = test[i]\n",
    "    loaded_model = link_predict(features.to(device)).to(device)\n",
    "    loaded_model.load_state_dict(torch.load('./model/link_prediction_{}.pt'.format(i + 1)))\n",
    "    loaded_model.to(device)\n",
    "    pred = predict(\n",
    "        model = loaded_model, \n",
    "        test = test_x\n",
    "    )\n",
    "    pred.to_csv('./upload/pred_{}.csv'.format(i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd2cb204-c505-4a15-966c-0a38a52643e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id      prob\n",
      "0     E10559  0.397379\n",
      "1      E4849  0.400328\n",
      "2      E3964  0.432398\n",
      "3       E542  0.377440\n",
      "4       E331  0.353298\n",
      "...      ...       ...\n",
      "2167   E2524  0.345380\n",
      "2168   E4324  0.421271\n",
      "2169   E1384  0.419238\n",
      "2170   E7582  0.369441\n",
      "2171   E5209  0.362468\n",
      "\n",
      "[2172 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test_x = torch.Tensor(np.array(test[0].iloc[::, 1:])).to(device)\n",
    "test_y = loaded_model(test_x)\n",
    "test_y = pd.DataFrame(test_y)\n",
    "pred = pd.concat([test[0], test_y], axis = 1)\n",
    "pred = pred.drop(['to', 'from'], axis = 1)\n",
    "pred.columns = ['id', 'prob']\n",
    "pred.to_csv('./upload/pred1.csv')\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb54c58-58f9-433b-ba1f-ef4125793cf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c6f535b-7803-44ca-ba91-fde1b94236fd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[1 / 50]: 100%|██████████| 79/79 [00:03<00:00, 23.41it/s, loss=tensor(13.9244, device='cuda:0', requires_grad=True), val_loss=tensor(0.2335, device='cuda:0')]\n",
      "Epoch[2 / 50]: 100%|██████████| 79/79 [00:03<00:00, 21.26it/s, loss=tensor(14.3060, device='cuda:0', requires_grad=True), val_loss=tensor(0.2337, device='cuda:0')]\n",
      "Epoch[3 / 50]: 100%|██████████| 79/79 [00:03<00:00, 21.89it/s, loss=tensor(14.8148, device='cuda:0', requires_grad=True), val_loss=tensor(0.2334, device='cuda:0')]\n",
      "Epoch[4 / 50]: 100%|██████████| 79/79 [00:03<00:00, 22.01it/s, loss=tensor(13.1973, device='cuda:0', requires_grad=True), val_loss=tensor(0.2338, device='cuda:0')]\n",
      "Epoch[5 / 50]: 100%|██████████| 79/79 [00:03<00:00, 20.03it/s, loss=tensor(14.2349, device='cuda:0', requires_grad=True), val_loss=tensor(0.2333, device='cuda:0')]\n",
      "Epoch[6 / 50]: 100%|██████████| 79/79 [00:03<00:00, 21.95it/s, loss=tensor(14.9486, device='cuda:0', requires_grad=True), val_loss=tensor(0.2335, device='cuda:0')]\n",
      "Epoch[7 / 50]: 100%|██████████| 79/79 [00:03<00:00, 22.69it/s, loss=tensor(14.5332, device='cuda:0', requires_grad=True), val_loss=tensor(0.2336, device='cuda:0')]\n",
      "Epoch[8 / 50]: 100%|██████████| 79/79 [00:03<00:00, 23.46it/s, loss=tensor(14.8441, device='cuda:0', requires_grad=True), val_loss=tensor(0.2334, device='cuda:0')]\n",
      "Epoch[9 / 50]: 100%|██████████| 79/79 [00:04<00:00, 18.52it/s, loss=tensor(14.0531, device='cuda:0', requires_grad=True), val_loss=tensor(0.2335, device='cuda:0')]\n",
      "Epoch[10 / 50]: 100%|██████████| 79/79 [00:03<00:00, 21.68it/s, loss=tensor(14.1537, device='cuda:0', requires_grad=True), val_loss=tensor(0.2338, device='cuda:0')]\n",
      "Epoch[11 / 50]: 100%|██████████| 79/79 [00:03<00:00, 20.67it/s, loss=tensor(13.6378, device='cuda:0', requires_grad=True), val_loss=tensor(0.2333, device='cuda:0')]\n",
      "Epoch[12 / 50]: 100%|██████████| 79/79 [00:04<00:00, 19.42it/s, loss=tensor(14.6416, device='cuda:0', requires_grad=True), val_loss=tensor(0.2332, device='cuda:0')]\n",
      "Epoch[13 / 50]: 100%|██████████| 79/79 [00:03<00:00, 20.27it/s, loss=tensor(13.8684, device='cuda:0', requires_grad=True), val_loss=tensor(0.2336, device='cuda:0')]\n",
      "Epoch[14 / 50]: 100%|██████████| 79/79 [00:04<00:00, 18.98it/s, loss=tensor(14.8124, device='cuda:0', requires_grad=True), val_loss=tensor(0.2332, device='cuda:0')]\n",
      "Epoch[15 / 50]: 100%|██████████| 79/79 [00:03<00:00, 19.99it/s, loss=tensor(14.9188, device='cuda:0', requires_grad=True), val_loss=tensor(0.2338, device='cuda:0')]\n",
      "Epoch[16 / 50]: 100%|██████████| 79/79 [00:03<00:00, 20.97it/s, loss=tensor(14.5361, device='cuda:0', requires_grad=True), val_loss=tensor(0.2334, device='cuda:0')]\n",
      "Epoch[17 / 50]: 100%|██████████| 79/79 [00:03<00:00, 21.77it/s, loss=tensor(15.1046, device='cuda:0', requires_grad=True), val_loss=tensor(0.2334, device='cuda:0')]\n",
      "Epoch[18 / 50]: 100%|██████████| 79/79 [00:03<00:00, 21.35it/s, loss=tensor(14.0759, device='cuda:0', requires_grad=True), val_loss=tensor(0.2330, device='cuda:0')]\n",
      "Epoch[19 / 50]: 100%|██████████| 79/79 [00:03<00:00, 21.67it/s, loss=tensor(14.7555, device='cuda:0', requires_grad=True), val_loss=tensor(0.2335, device='cuda:0')]\n",
      "Epoch[20 / 50]: 100%|██████████| 79/79 [00:03<00:00, 20.11it/s, loss=tensor(14.4584, device='cuda:0', requires_grad=True), val_loss=tensor(0.2334, device='cuda:0')]\n",
      "Epoch[21 / 50]: 100%|██████████| 79/79 [00:04<00:00, 19.14it/s, loss=tensor(13.5056, device='cuda:0', requires_grad=True), val_loss=tensor(0.2336, device='cuda:0')]\n",
      "Epoch[22 / 50]: 100%|██████████| 79/79 [00:03<00:00, 21.13it/s, loss=tensor(14.9480, device='cuda:0', requires_grad=True), val_loss=tensor(0.2335, device='cuda:0')]\n",
      "Epoch[23 / 50]: 100%|██████████| 79/79 [00:03<00:00, 23.90it/s, loss=tensor(14.7868, device='cuda:0', requires_grad=True), val_loss=tensor(0.2332, device='cuda:0')]\n",
      "Epoch[24 / 50]: 100%|██████████| 79/79 [00:03<00:00, 22.03it/s, loss=tensor(14.1887, device='cuda:0', requires_grad=True), val_loss=tensor(0.2338, device='cuda:0')]\n",
      "Epoch[25 / 50]: 100%|██████████| 79/79 [00:03<00:00, 22.22it/s, loss=tensor(15.8749, device='cuda:0', requires_grad=True), val_loss=tensor(0.2339, device='cuda:0')]\n",
      "Epoch[26 / 50]: 100%|██████████| 79/79 [00:03<00:00, 21.78it/s, loss=tensor(14.6753, device='cuda:0', requires_grad=True), val_loss=tensor(0.2338, device='cuda:0')]\n",
      "Epoch[27 / 50]: 100%|██████████| 79/79 [00:03<00:00, 20.36it/s, loss=tensor(14.9122, device='cuda:0', requires_grad=True), val_loss=tensor(0.2335, device='cuda:0')]\n",
      "Epoch[28 / 50]: 100%|██████████| 79/79 [00:03<00:00, 23.87it/s, loss=tensor(14.9563, device='cuda:0', requires_grad=True), val_loss=tensor(0.2338, device='cuda:0')]\n",
      "Epoch[29 / 50]: 100%|██████████| 79/79 [00:03<00:00, 21.99it/s, loss=tensor(14.4432, device='cuda:0', requires_grad=True), val_loss=tensor(0.2333, device='cuda:0')]\n",
      "Epoch[30 / 50]: 100%|██████████| 79/79 [00:03<00:00, 23.07it/s, loss=tensor(14.6280, device='cuda:0', requires_grad=True), val_loss=tensor(0.2332, device='cuda:0')]\n",
      "Epoch[31 / 50]: 100%|██████████| 79/79 [00:03<00:00, 23.14it/s, loss=tensor(14.4510, device='cuda:0', requires_grad=True), val_loss=tensor(0.2337, device='cuda:0')]\n",
      "Epoch[32 / 50]: 100%|██████████| 79/79 [00:03<00:00, 20.96it/s, loss=tensor(14.3407, device='cuda:0', requires_grad=True), val_loss=tensor(0.2338, device='cuda:0')]\n",
      "Epoch[33 / 50]: 100%|██████████| 79/79 [00:03<00:00, 23.32it/s, loss=tensor(14.7316, device='cuda:0', requires_grad=True), val_loss=tensor(0.2339, device='cuda:0')]\n",
      "Epoch[34 / 50]: 100%|██████████| 79/79 [00:03<00:00, 20.65it/s, loss=tensor(14.7623, device='cuda:0', requires_grad=True), val_loss=tensor(0.2336, device='cuda:0')]\n",
      "Epoch[35 / 50]: 100%|██████████| 79/79 [00:03<00:00, 22.17it/s, loss=tensor(13.9115, device='cuda:0', requires_grad=True), val_loss=tensor(0.2336, device='cuda:0')]\n",
      "Epoch[36 / 50]: 100%|██████████| 79/79 [00:04<00:00, 19.17it/s, loss=tensor(14.1087, device='cuda:0', requires_grad=True), val_loss=tensor(0.2335, device='cuda:0')]\n",
      "Epoch[37 / 50]: 100%|██████████| 79/79 [00:03<00:00, 23.27it/s, loss=tensor(14.4673, device='cuda:0', requires_grad=True), val_loss=tensor(0.2338, device='cuda:0')]\n",
      "Epoch[38 / 50]: 100%|██████████| 79/79 [00:03<00:00, 21.91it/s, loss=tensor(14.6052, device='cuda:0', requires_grad=True), val_loss=tensor(0.2333, device='cuda:0')]\n",
      "Epoch[39 / 50]: 100%|██████████| 79/79 [00:04<00:00, 19.38it/s, loss=tensor(14.5601, device='cuda:0', requires_grad=True), val_loss=tensor(0.2335, device='cuda:0')]\n",
      "Epoch[40 / 50]: 100%|██████████| 79/79 [00:03<00:00, 21.41it/s, loss=tensor(13.9434, device='cuda:0', requires_grad=True), val_loss=tensor(0.2335, device='cuda:0')]\n",
      "Epoch[41 / 50]: 100%|██████████| 79/79 [00:03<00:00, 22.01it/s, loss=tensor(14.2096, device='cuda:0', requires_grad=True), val_loss=tensor(0.2332, device='cuda:0')]\n",
      "Epoch[42 / 50]: 100%|██████████| 79/79 [00:03<00:00, 23.77it/s, loss=tensor(14.5338, device='cuda:0', requires_grad=True), val_loss=tensor(0.2338, device='cuda:0')]\n",
      "Epoch[43 / 50]: 100%|██████████| 79/79 [00:03<00:00, 22.08it/s, loss=tensor(14.0887, device='cuda:0', requires_grad=True), val_loss=tensor(0.2340, device='cuda:0')]\n",
      "Epoch[44 / 50]: 100%|██████████| 79/79 [00:03<00:00, 22.20it/s, loss=tensor(14.3609, device='cuda:0', requires_grad=True), val_loss=tensor(0.2333, device='cuda:0')]\n",
      "Epoch[45 / 50]: 100%|██████████| 79/79 [00:03<00:00, 20.46it/s, loss=tensor(14.0817, device='cuda:0', requires_grad=True), val_loss=tensor(0.2337, device='cuda:0')]\n",
      "Epoch[46 / 50]: 100%|██████████| 79/79 [00:03<00:00, 23.83it/s, loss=tensor(13.8072, device='cuda:0', requires_grad=True), val_loss=tensor(0.2336, device='cuda:0')]\n",
      "Epoch[47 / 50]: 100%|██████████| 79/79 [00:04<00:00, 19.18it/s, loss=tensor(14.8290, device='cuda:0', requires_grad=True), val_loss=tensor(0.2336, device='cuda:0')]\n",
      "Epoch[48 / 50]: 100%|██████████| 79/79 [00:03<00:00, 22.06it/s, loss=tensor(15.4042, device='cuda:0', requires_grad=True), val_loss=tensor(0.2338, device='cuda:0')]\n",
      "Epoch[49 / 50]: 100%|██████████| 79/79 [00:03<00:00, 22.90it/s, loss=tensor(14.1039, device='cuda:0', requires_grad=True), val_loss=tensor(0.2327, device='cuda:0')]\n",
      "Epoch[50 / 50]: 100%|██████████| 79/79 [00:03<00:00, 22.88it/s, loss=tensor(13.6862, device='cuda:0', requires_grad=True), val_loss=tensor(0.2338, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195.58005237579346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "model = link_predict(content[1].to(device)).to(device)\n",
    "# L2 regularization\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay = 1e-5)  \n",
    "loss_fn = nn.MSELoss()\n",
    "n_epochs = 50\n",
    "features = content[1]\n",
    "train_x = train[1]\n",
    "train_y = torch.Tensor(np.array(train_x.iloc[::, -1])).to(torch.float32)\n",
    "train_x = torch.Tensor(np.array(train_x.iloc[::, [1, 2]])).to(torch.float32)\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.33, random_state=42)\n",
    "train_dataset = Data.TensorDataset(train_x, train_y)\n",
    "val_dataset = Data.TensorDataset(val_x, val_y)\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = 4\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset = val_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = 4\n",
    ")\n",
    "sigma = 100\n",
    "\n",
    "ls_loss = training_loop( \n",
    "    model = model, \n",
    "    n_epochs = n_epochs,\n",
    "    optimizer = optimizer,\n",
    "    loss_fn = loss_fn,\n",
    "    features = features, \n",
    "    train_loader = train_loader, \n",
    "    val_loader = val_loader, \n",
    "    sigma = sigma\n",
    ")\n",
    "print(time.time() - s)\n",
    "torch.save(model.state_dict(), './model/d2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73937a20-6e09-4920-939a-fdad339c9a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "link_predict(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=3703, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = link_predict(content[1].to(device)).to(device)\n",
    "loaded_model.load_state_dict(torch.load('./model/d2.pt'))\n",
    "loaded_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2baf078d-992a-4ece-97c3-cf7a2a6f5b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id      prob\n",
      "0     E3064  0.364130\n",
      "1      E298  0.342586\n",
      "2     E3512  0.343670\n",
      "3     E5670  0.358549\n",
      "4     E5005  0.379004\n",
      "...     ...       ...\n",
      "1881  E9179  0.360409\n",
      "1882  E5003  0.409637\n",
      "1883  E5081  0.352319\n",
      "1884  E4705  0.358406\n",
      "1885  E1012  0.358096\n",
      "\n",
      "[1886 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test_x = torch.Tensor(np.array(test[1].iloc[::, 1:])).to(device)\n",
    "test_y = loaded_model(test_x)\n",
    "test_y = pd.DataFrame(test_y)\n",
    "pred = pd.concat([test[1], test_y], axis = 1)\n",
    "pred = pred.drop(['to', 'from'], axis = 1)\n",
    "pred.columns = ['id', 'prob']\n",
    "pred.to_csv('./upload/pred2.csv')\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35dfd49-8076-4d12-bdce-bc3e85037d36",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd540a4c-5bc9-4051-8151-01d3e3ed6627",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[1 / 50]: 100%|██████████| 27/27 [00:01<00:00, 20.09it/s, loss=tensor(14.4092, device='cuda:0', requires_grad=True), val_loss=tensor(0.2723, device='cuda:0')]\n",
      "Epoch[2 / 50]: 100%|██████████| 27/27 [00:01<00:00, 18.12it/s, loss=tensor(16.7010, device='cuda:0', requires_grad=True), val_loss=tensor(0.2721, device='cuda:0')]\n",
      "Epoch[3 / 50]: 100%|██████████| 27/27 [00:01<00:00, 18.34it/s, loss=tensor(16.8061, device='cuda:0', requires_grad=True), val_loss=tensor(0.2722, device='cuda:0')]\n",
      "Epoch[4 / 50]: 100%|██████████| 27/27 [00:01<00:00, 19.25it/s, loss=tensor(14.5528, device='cuda:0', requires_grad=True), val_loss=tensor(0.2721, device='cuda:0')]\n",
      "Epoch[5 / 50]: 100%|██████████| 27/27 [00:01<00:00, 19.70it/s, loss=tensor(16.5008, device='cuda:0', requires_grad=True), val_loss=tensor(0.2721, device='cuda:0')]\n",
      "Epoch[6 / 50]: 100%|██████████| 27/27 [00:01<00:00, 16.94it/s, loss=tensor(13.8822, device='cuda:0', requires_grad=True), val_loss=tensor(0.2719, device='cuda:0')]\n",
      "Epoch[7 / 50]: 100%|██████████| 27/27 [00:01<00:00, 18.65it/s, loss=tensor(16.8188, device='cuda:0', requires_grad=True), val_loss=tensor(0.2723, device='cuda:0')]\n",
      "Epoch[8 / 50]: 100%|██████████| 27/27 [00:01<00:00, 19.59it/s, loss=tensor(16.9615, device='cuda:0', requires_grad=True), val_loss=tensor(0.2720, device='cuda:0')]\n",
      "Epoch[9 / 50]: 100%|██████████| 27/27 [00:01<00:00, 19.18it/s, loss=tensor(14.7530, device='cuda:0', requires_grad=True), val_loss=tensor(0.2722, device='cuda:0')]\n",
      "Epoch[10 / 50]: 100%|██████████| 27/27 [00:01<00:00, 17.94it/s, loss=tensor(15.3560, device='cuda:0', requires_grad=True), val_loss=tensor(0.2726, device='cuda:0')]\n",
      "Epoch[11 / 50]: 100%|██████████| 27/27 [00:01<00:00, 19.55it/s, loss=tensor(15.4527, device='cuda:0', requires_grad=True), val_loss=tensor(0.2719, device='cuda:0')]\n",
      "Epoch[12 / 50]: 100%|██████████| 27/27 [00:01<00:00, 16.07it/s, loss=tensor(15.7625, device='cuda:0', requires_grad=True), val_loss=tensor(0.2722, device='cuda:0')]\n",
      "Epoch[13 / 50]: 100%|██████████| 27/27 [00:01<00:00, 20.04it/s, loss=tensor(15.5791, device='cuda:0', requires_grad=True), val_loss=tensor(0.2721, device='cuda:0')]\n",
      "Epoch[14 / 50]: 100%|██████████| 27/27 [00:01<00:00, 17.06it/s, loss=tensor(15.7891, device='cuda:0', requires_grad=True), val_loss=tensor(0.2722, device='cuda:0')]\n",
      "Epoch[15 / 50]: 100%|██████████| 27/27 [00:01<00:00, 19.26it/s, loss=tensor(15.6700, device='cuda:0', requires_grad=True), val_loss=tensor(0.2720, device='cuda:0')]\n",
      "Epoch[16 / 50]: 100%|██████████| 27/27 [00:01<00:00, 18.35it/s, loss=tensor(15.7860, device='cuda:0', requires_grad=True), val_loss=tensor(0.2721, device='cuda:0')]\n",
      "Epoch[17 / 50]: 100%|██████████| 27/27 [00:01<00:00, 15.67it/s, loss=tensor(16.2031, device='cuda:0', requires_grad=True), val_loss=tensor(0.2723, device='cuda:0')]\n",
      "Epoch[18 / 50]: 100%|██████████| 27/27 [00:01<00:00, 17.64it/s, loss=tensor(15.2655, device='cuda:0', requires_grad=True), val_loss=tensor(0.2720, device='cuda:0')]\n",
      "Epoch[19 / 50]: 100%|██████████| 27/27 [00:01<00:00, 17.66it/s, loss=tensor(14.2380, device='cuda:0', requires_grad=True), val_loss=tensor(0.2720, device='cuda:0')]\n",
      "Epoch[20 / 50]: 100%|██████████| 27/27 [00:01<00:00, 18.82it/s, loss=tensor(12.5781, device='cuda:0', requires_grad=True), val_loss=tensor(0.2721, device='cuda:0')]\n",
      "Epoch[21 / 50]: 100%|██████████| 27/27 [00:01<00:00, 17.62it/s, loss=tensor(13.5242, device='cuda:0', requires_grad=True), val_loss=tensor(0.2717, device='cuda:0')]\n",
      "Epoch[22 / 50]: 100%|██████████| 27/27 [00:01<00:00, 17.68it/s, loss=tensor(13.9601, device='cuda:0', requires_grad=True), val_loss=tensor(0.2724, device='cuda:0')]\n",
      "Epoch[23 / 50]: 100%|██████████| 27/27 [00:01<00:00, 21.00it/s, loss=tensor(15.2954, device='cuda:0', requires_grad=True), val_loss=tensor(0.2719, device='cuda:0')]\n",
      "Epoch[24 / 50]: 100%|██████████| 27/27 [00:01<00:00, 19.90it/s, loss=tensor(14.6075, device='cuda:0', requires_grad=True), val_loss=tensor(0.2720, device='cuda:0')]\n",
      "Epoch[25 / 50]: 100%|██████████| 27/27 [00:01<00:00, 18.04it/s, loss=tensor(17.4487, device='cuda:0', requires_grad=True), val_loss=tensor(0.2721, device='cuda:0')]\n",
      "Epoch[26 / 50]: 100%|██████████| 27/27 [00:01<00:00, 16.24it/s, loss=tensor(18.4412, device='cuda:0', requires_grad=True), val_loss=tensor(0.2721, device='cuda:0')]\n",
      "Epoch[27 / 50]: 100%|██████████| 27/27 [00:01<00:00, 19.49it/s, loss=tensor(15.2115, device='cuda:0', requires_grad=True), val_loss=tensor(0.2724, device='cuda:0')]\n",
      "Epoch[28 / 50]: 100%|██████████| 27/27 [00:01<00:00, 19.56it/s, loss=tensor(17.6018, device='cuda:0', requires_grad=True), val_loss=tensor(0.2721, device='cuda:0')]\n",
      "Epoch[29 / 50]: 100%|██████████| 27/27 [00:01<00:00, 17.74it/s, loss=tensor(13.6373, device='cuda:0', requires_grad=True), val_loss=tensor(0.2721, device='cuda:0')]\n",
      "Epoch[30 / 50]: 100%|██████████| 27/27 [00:01<00:00, 16.32it/s, loss=tensor(15.4482, device='cuda:0', requires_grad=True), val_loss=tensor(0.2722, device='cuda:0')]\n",
      "Epoch[31 / 50]: 100%|██████████| 27/27 [00:01<00:00, 18.39it/s, loss=tensor(16.4334, device='cuda:0', requires_grad=True), val_loss=tensor(0.2723, device='cuda:0')]\n",
      "Epoch[32 / 50]: 100%|██████████| 27/27 [00:01<00:00, 20.30it/s, loss=tensor(15.7501, device='cuda:0', requires_grad=True), val_loss=tensor(0.2723, device='cuda:0')]\n",
      "Epoch[33 / 50]: 100%|██████████| 27/27 [00:01<00:00, 18.53it/s, loss=tensor(15.8792, device='cuda:0', requires_grad=True), val_loss=tensor(0.2719, device='cuda:0')]\n",
      "Epoch[34 / 50]: 100%|██████████| 27/27 [00:01<00:00, 19.90it/s, loss=tensor(16.2734, device='cuda:0', requires_grad=True), val_loss=tensor(0.2722, device='cuda:0')]\n",
      "Epoch[35 / 50]: 100%|██████████| 27/27 [00:01<00:00, 17.82it/s, loss=tensor(16.0907, device='cuda:0', requires_grad=True), val_loss=tensor(0.2719, device='cuda:0')]\n",
      "Epoch[36 / 50]: 100%|██████████| 27/27 [00:01<00:00, 18.31it/s, loss=tensor(14.3187, device='cuda:0', requires_grad=True), val_loss=tensor(0.2717, device='cuda:0')]\n",
      "Epoch[37 / 50]: 100%|██████████| 27/27 [00:01<00:00, 19.26it/s, loss=tensor(15.0206, device='cuda:0', requires_grad=True), val_loss=tensor(0.2719, device='cuda:0')]\n",
      "Epoch[38 / 50]: 100%|██████████| 27/27 [00:01<00:00, 18.87it/s, loss=tensor(17.6404, device='cuda:0', requires_grad=True), val_loss=tensor(0.2718, device='cuda:0')]\n",
      "Epoch[39 / 50]: 100%|██████████| 27/27 [00:01<00:00, 20.46it/s, loss=tensor(16.3029, device='cuda:0', requires_grad=True), val_loss=tensor(0.2725, device='cuda:0')]\n",
      "Epoch[40 / 50]: 100%|██████████| 27/27 [00:01<00:00, 19.73it/s, loss=tensor(17.2640, device='cuda:0', requires_grad=True), val_loss=tensor(0.2725, device='cuda:0')]\n",
      "Epoch[41 / 50]: 100%|██████████| 27/27 [00:01<00:00, 17.54it/s, loss=tensor(14.2896, device='cuda:0', requires_grad=True), val_loss=tensor(0.2721, device='cuda:0')]\n",
      "Epoch[42 / 50]: 100%|██████████| 27/27 [00:01<00:00, 17.37it/s, loss=tensor(17.9945, device='cuda:0', requires_grad=True), val_loss=tensor(0.2720, device='cuda:0')]\n",
      "Epoch[43 / 50]: 100%|██████████| 27/27 [00:01<00:00, 17.82it/s, loss=tensor(15.4734, device='cuda:0', requires_grad=True), val_loss=tensor(0.2719, device='cuda:0')]\n",
      "Epoch[44 / 50]: 100%|██████████| 27/27 [00:01<00:00, 18.21it/s, loss=tensor(17.1830, device='cuda:0', requires_grad=True), val_loss=tensor(0.2723, device='cuda:0')]\n",
      "Epoch[45 / 50]: 100%|██████████| 27/27 [00:01<00:00, 18.46it/s, loss=tensor(15.6548, device='cuda:0', requires_grad=True), val_loss=tensor(0.2720, device='cuda:0')]\n",
      "Epoch[46 / 50]: 100%|██████████| 27/27 [00:01<00:00, 17.67it/s, loss=tensor(14.3168, device='cuda:0', requires_grad=True), val_loss=tensor(0.2719, device='cuda:0')]\n",
      "Epoch[47 / 50]: 100%|██████████| 27/27 [00:01<00:00, 17.72it/s, loss=tensor(18.5129, device='cuda:0', requires_grad=True), val_loss=tensor(0.2720, device='cuda:0')]\n",
      "Epoch[48 / 50]: 100%|██████████| 27/27 [00:01<00:00, 20.03it/s, loss=tensor(14.7814, device='cuda:0', requires_grad=True), val_loss=tensor(0.2723, device='cuda:0')]\n",
      "Epoch[49 / 50]: 100%|██████████| 27/27 [00:01<00:00, 18.61it/s, loss=tensor(17.1668, device='cuda:0', requires_grad=True), val_loss=tensor(0.2723, device='cuda:0')]\n",
      "Epoch[50 / 50]: 100%|██████████| 27/27 [00:01<00:00, 17.04it/s, loss=tensor(16.1061, device='cuda:0', requires_grad=True), val_loss=tensor(0.2719, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.13452434539795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "model = link_predict(content[2].to(device)).to(device)\n",
    "# L2 regularization\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay = 1e-5)  \n",
    "loss_fn = nn.MSELoss()\n",
    "n_epochs = 50\n",
    "features = content[2]\n",
    "train_x = train[2]\n",
    "train_y = torch.Tensor(np.array(train_x.iloc[::, -1])).to(torch.float32)\n",
    "train_x = torch.Tensor(np.array(train_x.iloc[::, [1, 2]])).to(torch.float32)\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.33, random_state=42)\n",
    "train_dataset = Data.TensorDataset(train_x, train_y)\n",
    "val_dataset = Data.TensorDataset(val_x, val_y)\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = 4\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset = val_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = 4\n",
    ")\n",
    "sigma = 100\n",
    "\n",
    "ls_loss = training_loop( \n",
    "    model = model, \n",
    "    n_epochs = n_epochs,\n",
    "    optimizer = optimizer,\n",
    "    loss_fn = loss_fn,\n",
    "    features = features, \n",
    "    train_loader = train_loader, \n",
    "    val_loader = val_loader, \n",
    "    sigma = sigma\n",
    ")\n",
    "print(time.time() - s)\n",
    "torch.save(model.state_dict(), './model/d3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c4e6dac-9e12-4edd-8b67-a86eb9806bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "link_predict(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=1703, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = link_predict(content[2].to(device)).to(device)\n",
    "loaded_model.load_state_dict(torch.load('./model/d3.pt'))\n",
    "loaded_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "510c678d-4a90-40f8-90ac-dd35d73f6cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id      prob\n",
      "0     E370  0.362547\n",
      "1     E667  0.368623\n",
      "2    E3190  0.410616\n",
      "3     E848  0.390194\n",
      "4    E2161  0.383467\n",
      "..     ...       ...\n",
      "639   E492  0.422233\n",
      "640  E3055  0.403786\n",
      "641  E1271  0.396863\n",
      "642  E2199  0.351590\n",
      "643  E2186  0.389092\n",
      "\n",
      "[644 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test_x = torch.Tensor(np.array(test[2].iloc[::, 1:])).to(device)\n",
    "test_y = loaded_model(test_x)\n",
    "test_y = pd.DataFrame(test_y)\n",
    "pred = pd.concat([test[2], test_y], axis = 1)\n",
    "pred = pred.drop(['to', 'from'], axis = 1)\n",
    "pred.columns = ['id', 'prob']\n",
    "pred.to_csv('./upload/pred3.csv')\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ba382e-d9d7-4437-b35b-682282d077e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800737e6-a3d0-4856-85c3-96bb4e8a81a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba424e28-7ac9-45bc-8081-a4ca827bf295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515fa9fd-b13f-43c9-a447-9341e19711d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterlab",
   "language": "python",
   "name": "jupyterlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
