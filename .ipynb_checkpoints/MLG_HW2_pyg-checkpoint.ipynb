{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLG HW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(120000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 120 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, time, torch, json\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# from torch_geometric.utils import accuracy,sparse_mx_to_torch_sparse_tensor\n",
    "import torch_geometric.utils \n",
    "# from models.GCN import GCN\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm, trange\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# from torchvision import datasets, transforms\n",
    "# import torch.utils.data as Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.data import Data, Dataset\n",
    "# test \n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "%autosave 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content :\n",
      "    1     2     3     4     5     6     7     8     9     10    ...  1424  \\\n",
      "0                                                              ...         \n",
      "0     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "1     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "\n",
      "   1425  1426  1427  1428  1429  1430  1431  1432  1433  \n",
      "0                                                        \n",
      "0     0     0     0     0     0     0     0     0     0  \n",
      "1     1     0     0     0     0     0     0     0     0  \n",
      "\n",
      "[2 rows x 1433 columns]\n",
      "test_ :\n",
      "        id    to  from\n",
      "0  E10559  2323  2673\n",
      "1   E4849    81  1634\n",
      "train_ : \n",
      "        id    to  from  label\n",
      "0  E10311  2399  2339      0\n",
      "1  E10255  2397  1144      1\n",
      "edge_index : \n",
      "      to  from\n",
      "0  2397  1144\n",
      "1  2450  1312\n",
      "upload : \n",
      "        id  prob\n",
      "0  E10559   0.5\n",
      "1   E4849   0.5\n"
     ]
    }
   ],
   "source": [
    "content = []\n",
    "test_ = []\n",
    "train_ = []\n",
    "upload = []\n",
    "edge_index = [] \n",
    "for i in range(3):\n",
    "    os.chdir('/home/rita/111/111-2MLG/HW2/dataset{}'.format(i + 1))\n",
    "    temp = pd.read_csv('./content.csv', header = None, sep = '\\t')\n",
    "    temp.sort_values(by = [0], inplace = True)\n",
    "    temp.set_index([0], inplace = True)\n",
    "    # temp = torch.Tensor(np.array(temp)).to(torch.float32)\n",
    "    # print(temp.shape)\n",
    "    content.append(temp)\n",
    "    test_.append(pd.read_csv('./test.csv'))\n",
    "    temp = pd.read_csv('./train.csv')\n",
    "    # print(temp.shape)\n",
    "    train_.append(temp)\n",
    "    temp = temp[temp.label == 1]\n",
    "    temp = temp[['to', 'from']]\n",
    "    temp = temp.reset_index(drop = True)\n",
    "    # print(temp.shape)\n",
    "    edge_index.append(temp)\n",
    "    upload.append(pd.read_csv('./upload.csv'))\n",
    "print('content :\\n', content[0][:2])\n",
    "print('test_ :\\n', test_[0].head(2))\n",
    "print('train_ : \\n', train_[0].head(2))\n",
    "print('edge_index : \\n', edge_index[0].head(2))\n",
    "print('upload : \\n', upload[0].head(2))\n",
    "os.chdir('/home/rita/111/111-2MLG/HW2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "(2708, 1433)\n",
      "torch.Size([2708, 1433])\n"
     ]
    }
   ],
   "source": [
    "# content preprocessing\n",
    "new_features = []\n",
    "for j in range(len(content)) :\n",
    "    t = torch.Tensor(np.array(content[j]))\n",
    "    features_entropy = []\n",
    "    for i in range(t.shape[1]) :\n",
    "        temp = t.T[i]\n",
    "        t1 = torch.sum(temp == 0) / len(temp)\n",
    "        t2 = torch.sum(temp == 1) / len(temp)\n",
    "        temp = torch.tensor([t1, t2])\n",
    "        temp = entropy(temp)\n",
    "        if (temp == 0) :\n",
    "            temp = 0\n",
    "        else :\n",
    "            temp = 1 / temp\n",
    "        features_entropy.append(temp)\n",
    "    features_entropy = torch.tensor(features_entropy).reshape(1, -1)\n",
    "    t = t * features_entropy\n",
    "    t = t.type(torch.float32)\n",
    "    new_features.append(t)\n",
    "print(new_features[0][:2])\n",
    "print(content[0].shape)\n",
    "print(new_features[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 8686], edge_label_index=[2, 4324], edge_label=[4324])\n",
      "Data(x=[2708, 1433], edge_index=[2, 8686], edge_label_index=[2, 2172])\n"
     ]
    }
   ],
   "source": [
    "# change to Data.Data\n",
    "\n",
    "# data = {\n",
    "#     'num_features' : content[i].shape[1], \n",
    "#     'num_nodes' : content[i].shape[0], \n",
    "#     'x' : content[i], \n",
    "#     'edge_index' : torch.Tensor(np.array(train_[i].iloc[::, 1:3])).T.type(torch.long), \n",
    "#     'edge_label_index' : torch.Tensor(np.array(train_[i][train_[i].label == 1].iloc[::, 1:3])).T.type(torch.long), \n",
    "#     'edge_label' : torch.Tensor(np.array(train_[i][train_[i].label == 1].iloc[::, -1]))\n",
    "# }\n",
    "\n",
    "train_pyg = {}\n",
    "test_pyg = {}\n",
    "for i in range(3):\n",
    "    # x = torch.Tensor(np.array(content[i]))\n",
    "    x = new_features[i]\n",
    "    train_edge_index = torch.Tensor(np.array(train_[i].iloc[::, 1:3])).T.type(torch.long)\n",
    "    train_edge_label_index = torch.Tensor(np.array(train_[i][train_[i].label == 1].iloc[::, 1:3])).T.type(torch.long)\n",
    "    train_edge_label = torch.Tensor(np.array(train_[i][train_[i].label == 1].iloc[::, -1]))\n",
    "    test_edge_label_index = torch.Tensor(np.array(test_[i].iloc[::, 1:3]).astype(float)).T.type(torch.long)\n",
    "    train_data = Data(x = x, edge_index = train_edge_index, edge_label_index = train_edge_label_index, edge_label = train_edge_label)\n",
    "    test_data = Data(x = x, edge_index = train_edge_index, edge_label_index = test_edge_label_index)\n",
    "\n",
    "    train_pyg[i] = train_data.to(device)\n",
    "    test_pyg[i] = test_data.to(device)\n",
    "print(train_pyg[0])\n",
    "print(test_pyg[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/rita/111/111-2MLG/HW2/MLG_HW2_pyg.ipynb 儲存格 5\u001b[0m in \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnetai_940_2/home/rita/111/111-2MLG/HW2/MLG_HW2_pyg.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m CUDA_LAUNCH_BLOCKING\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnetai_940_2/home/rita/111/111-2MLG/HW2/MLG_HW2_pyg.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m) :\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bnetai_940_2/home/rita/111/111-2MLG/HW2/MLG_HW2_pyg.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     train_pyg[i] \u001b[39m=\u001b[39m transform(train_pyg[i])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnetai_940_2/home/rita/111/111-2MLG/HW2/MLG_HW2_pyg.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     test_pyg[i] \u001b[39m=\u001b[39m transform(test_pyg[i])\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/torch_geometric/transforms/compose.py:24\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     22\u001b[0m         data \u001b[39m=\u001b[39m [transform(d) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data]\n\u001b[1;32m     23\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 24\u001b[0m         data \u001b[39m=\u001b[39m transform(data)\n\u001b[1;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/torch_geometric/transforms/to_device.py:36\u001b[0m, in \u001b[0;36mToDevice.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m     33\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     34\u001b[0m     data: Union[Data, HeteroData],\n\u001b[1;32m     35\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Data, HeteroData]:\n\u001b[0;32m---> 36\u001b[0m     \u001b[39mreturn\u001b[39;00m data\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice, \u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattrs,\n\u001b[1;32m     37\u001b[0m                    non_blocking\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnon_blocking)\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/torch_geometric/data/data.py:251\u001b[0m, in \u001b[0;36mBaseData.to\u001b[0;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto\u001b[39m(\u001b[39mself\u001b[39m, device: Union[\u001b[39mint\u001b[39m, \u001b[39mstr\u001b[39m], \u001b[39m*\u001b[39margs: List[\u001b[39mstr\u001b[39m],\n\u001b[1;32m    248\u001b[0m        non_blocking: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    249\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\n\u001b[1;32m    252\u001b[0m         \u001b[39mlambda\u001b[39;49;00m x: x\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39;49mdevice, non_blocking\u001b[39m=\u001b[39;49mnon_blocking), \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/torch_geometric/data/data.py:234\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39mfor\u001b[39;00m store \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstores:\n\u001b[0;32m--> 234\u001b[0m     store\u001b[39m.\u001b[39;49mapply(func, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/torch_geometric/data/storage.py:163\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems(\u001b[39m*\u001b[39margs):\n\u001b[0;32m--> 163\u001b[0m     \u001b[39mself\u001b[39m[key] \u001b[39m=\u001b[39m recursive_apply(value, func)\n\u001b[1;32m    164\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/torch_geometric/data/storage.py:523\u001b[0m, in \u001b[0;36mrecursive_apply\u001b[0;34m(data, func)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecursive_apply\u001b[39m(data: Any, func: Callable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    522\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Tensor):\n\u001b[0;32m--> 523\u001b[0m         \u001b[39mreturn\u001b[39;00m func(data)\n\u001b[1;32m    524\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mrnn\u001b[39m.\u001b[39mPackedSequence):\n\u001b[1;32m    525\u001b[0m         \u001b[39mreturn\u001b[39;00m func(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/torch_geometric/data/data.py:252\u001b[0m, in \u001b[0;36mBaseData.to.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto\u001b[39m(\u001b[39mself\u001b[39m, device: Union[\u001b[39mint\u001b[39m, \u001b[39mstr\u001b[39m], \u001b[39m*\u001b[39margs: List[\u001b[39mstr\u001b[39m],\n\u001b[1;32m    248\u001b[0m        non_blocking: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    249\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply(\n\u001b[0;32m--> 252\u001b[0m         \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39;49mdevice, non_blocking\u001b[39m=\u001b[39;49mnon_blocking), \u001b[39m*\u001b[39margs)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    # T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "    #                   add_negative_train_samples=False),\n",
    "])\n",
    "# CUDA_LAUNCH_BLOCKING=1 \n",
    "for i in range(3) :\n",
    "    train_pyg[i] = transform(train_pyg[i])\n",
    "    test_pyg[i] = transform(test_pyg[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cora Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(\"/tmp/Cora\", name = \"Cora\")\n",
    "num_nodes = dataset.data.num_nodes \n",
    "# For num. edges see: \n",
    "# - https://github.com/pyg-team/pytorch_geometric/issues/343 \n",
    "# - https://github.com/pyg-team/pytorch_geometric/issues/852 \n",
    "num_edges = dataset.data.num_edges // 2 \n",
    "train_len = dataset[0].train_mask.sum() \n",
    "val_len = dataset[0].val_mask.sum() \n",
    "test_len = dataset[0].test_mask.sum() \n",
    "other_len = num_nodes - train_len - val_len - test_len \n",
    "print(f\"Dataset: {dataset.name}\") \n",
    "print(f\"Num. nodes: {num_nodes} (train={train_len}, val={val_len}, test={test_len}, other={other_len})\") \n",
    "print(f\"Num. edges: {num_edges}\") \n",
    "print(f\"Num. node features: {dataset.num_node_features}\") \n",
    "print(f\"Num. classes: {dataset.num_classes}\") \n",
    "print(f\"Dataset len.: {dataset.len()}\")\n",
    "\n",
    "dataset = Planetoid(\"/tmp/Cora\", name=\"Cora\") \n",
    "print(f\"Sum of row values without normalization: {dataset[0].x.sum(dim=-1)}\") \n",
    " \n",
    "dataset = Planetoid(\"/tmp/Cora\", name=\"Cora\", transform=T.NormalizeFeatures()) \n",
    "print(f\"Sum of row values with normalization: {dataset[0].x.sum(dim=-1)}\")\n",
    "\n",
    "print(dataset[0])\n",
    "print(dataset)\n",
    "print(dataset[0].keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      add_negative_train_samples=False),\n",
    "])\n",
    "# path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', 'Planetoid')\n",
    "# dataset = Planetoid(path, name='Cora', transform=transform)\n",
    "dataset = Planetoid(\"/tmp/Cora\", name = \"Cora\", transform=transform)\n",
    "# After applying the `RandomLinkSplit` transform, the data is transformed from\n",
    "# a data object to a list of tuples (train_data, val_data, test_data), with\n",
    "# each element representing the corresponding split.\n",
    "train_data, val_data, test_data = dataset[0]\n",
    "\n",
    "# print(train_data)\n",
    "# print(val_data)\n",
    "# print(test_data)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dataset.num_features :', dataset.num_features)\n",
    "print('train_data.x : ', train_data.x)\n",
    "# 所有的 edge (0, 1)\n",
    "print('train_data.edge_index : ', train_data.edge_index.shape)\n",
    "print('train_data.edge_index : ', train_data.edge_index)\n",
    "# label = 1 的 edge\n",
    "print('train_data.edge_label_index : ', train_data.edge_label_index.shape)\n",
    "print('train_data.edge_label_index : ', train_data.edge_label_index)\n",
    "print('train_data.edge_label_index.size(1) : ', train_data.edge_label_index.size(1))\n",
    "print('train_data.edge_label : ', train_data.edge_label.shape)\n",
    "print('train_data.edge_label : ', train_data.edge_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "\n",
    "model = Net(dataset.num_features, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "\n",
    "z = model.encode(test_data.x, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For HW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels = 128, out_channels = 64):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "def fit(model, optim, loss_fn, train_data):\n",
    "    model.train()\n",
    "    optim.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "    # z = model.encode(data['x'].to(device), data['edge_index'].to(device))\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "    # neg_edge_index = negative_sampling(\n",
    "    #     edge_index= data['edge_index'], num_nodes= data['num_nodes'],\n",
    "    #     num_neg_samples=data['edge_label_index'].size(1), method='sparse')\n",
    "\n",
    "    # edge_label_index = torch.cat(\n",
    "    #     [data['edge_label_index'], neg_edge_index],\n",
    "    #     dim=-1,\n",
    "    # )\n",
    "    # edge_label = torch.cat([\n",
    "    #     data['edge_label'],\n",
    "    #     data['edge_label'].new_zeros(neg_edge_index.size(1))\n",
    "    # ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = loss_fn(out, edge_label.to(device))\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def test(data):\n",
    "#     model.eval()\n",
    "#     z = model.encode(data['x'], data['edge_index'])\n",
    "#     out = model.decode(z, data['edge_label_index']).view(-1).sigmoid()\n",
    "#     return roc_auc_score(data['edge_label'].cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "def training_loop(data, n_epochs):\n",
    "    model = Net(in_channels = data.x.shape[1]).to(device)\n",
    "    optim = torch.optim.Adam(params=model.parameters(), lr=1e-2)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = fit(\n",
    "            model = model, \n",
    "            optim = optim, \n",
    "            loss_fn = loss_fn, \n",
    "            train_data = data\n",
    "        )\n",
    "        if epoch % 100 == 0 :\n",
    "            print('Epoch : {}, Loss : {}'.format(epoch, loss))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# model = Net(dataset.num_features, 128, 64).to(device)\n",
    "# model = Net(content[i].shape[1], 128, 64).to(device)\n",
    "# # optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "# optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "# criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# best_val_auc = final_test_auc = 0\n",
    "# for epoch in range(1, 11):\n",
    "#     loss = train(data = data)\n",
    "# #     val_auc = test(val_data)\n",
    "# #     test_auc = test(test_data)\n",
    "# #     if val_auc > best_val_auc:\n",
    "# #         best_val_auc = val_auc\n",
    "# #         final_test_auc = test_auc\n",
    "# #     print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "# #           f'Test: {test_auc:.4f}')\n",
    "#     print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "\n",
    "# print(f'Final Test: {final_test_auc:.4f}')\n",
    "\n",
    "# z = model.encode(test_data.x, test_data.edge_index)\n",
    "# final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test) :\n",
    "    z = model.encode(test.x, test.edge_index)\n",
    "    pred = torch.sigmoid(model.decode(z, test.edge_label_index))\n",
    "    \n",
    "\n",
    "    # test_x = torch.Tensor(np.array(test.iloc[::, 1:])).to(device)\n",
    "    # test_y = loaded_model(test_x)\n",
    "    # test_y = pd.DataFrame(test_y)\n",
    "    # pred = pd.concat([test, test_y], axis = 1)\n",
    "    # pred = pred.drop(['to', 'from'], axis = 1)\n",
    "    # pred.columns = ['id', 'prob']\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Loss : 0.6486372351646423\n",
      "Epoch : 200, Loss : 0.6396380662918091\n",
      "Epoch : 300, Loss : 0.6325972676277161\n",
      "Epoch : 400, Loss : 0.629967987537384\n",
      "Epoch : 500, Loss : 0.6246803998947144\n",
      "Epoch : 600, Loss : 0.6119992136955261\n",
      "Epoch : 700, Loss : 0.6012597680091858\n",
      "Epoch : 800, Loss : 0.5940280556678772\n",
      "Epoch : 900, Loss : 0.5968967080116272\n",
      "Epoch : 1000, Loss : 0.5840685963630676\n",
      "Epoch : 1100, Loss : 0.5907110571861267\n",
      "Epoch : 1200, Loss : 0.5803226232528687\n",
      "Epoch : 1300, Loss : 0.5696519613265991\n",
      "Epoch : 1400, Loss : 0.5440661311149597\n",
      "Epoch : 1500, Loss : 0.5467347502708435\n",
      "Epoch : 1600, Loss : 0.5280864238739014\n",
      "Epoch : 1700, Loss : 0.524951696395874\n",
      "Epoch : 1800, Loss : 0.5239405632019043\n",
      "Epoch : 1900, Loss : 0.520146906375885\n",
      "Epoch : 2000, Loss : 0.5427640080451965\n",
      "Epoch : 2100, Loss : 0.5093306303024292\n",
      "Epoch : 2200, Loss : 0.5102956891059875\n",
      "Epoch : 2300, Loss : 0.5017051696777344\n",
      "Epoch : 2400, Loss : 0.5027053952217102\n",
      "Epoch : 2500, Loss : 0.49346524477005005\n",
      "Epoch : 2600, Loss : 0.4924864172935486\n",
      "Epoch : 2700, Loss : 0.49058642983436584\n",
      "Epoch : 2800, Loss : 0.48883503675460815\n",
      "Epoch : 2900, Loss : 0.4817543923854828\n",
      "Epoch : 3000, Loss : 0.48455703258514404\n",
      "torch.Size([2172])\n",
      "Epoch : 100, Loss : 0.6554606556892395\n",
      "Epoch : 200, Loss : 0.6569650173187256\n",
      "Epoch : 300, Loss : 0.654132068157196\n",
      "Epoch : 400, Loss : 0.6565538644790649\n",
      "Epoch : 500, Loss : 0.6464093327522278\n",
      "Epoch : 600, Loss : 0.6517823934555054\n",
      "Epoch : 700, Loss : 0.6500006914138794\n",
      "Epoch : 800, Loss : 0.6497449278831482\n",
      "Epoch : 900, Loss : 0.6527535915374756\n",
      "Epoch : 1000, Loss : 0.6548810601234436\n",
      "Epoch : 1100, Loss : 0.6623992323875427\n",
      "Epoch : 1200, Loss : 0.6570077538490295\n",
      "Epoch : 1300, Loss : 0.6578763723373413\n",
      "Epoch : 1400, Loss : 0.6572409272193909\n",
      "Epoch : 1500, Loss : 0.6714860200881958\n",
      "Epoch : 1600, Loss : 0.6606258749961853\n",
      "Epoch : 1700, Loss : 0.6622625589370728\n",
      "Epoch : 1800, Loss : 0.6638441681861877\n",
      "Epoch : 1900, Loss : 0.6640115976333618\n",
      "Epoch : 2000, Loss : 0.6639981269836426\n",
      "Epoch : 2100, Loss : 0.665981113910675\n",
      "Epoch : 2200, Loss : 0.663749098777771\n",
      "Epoch : 2300, Loss : 0.669445812702179\n",
      "Epoch : 2400, Loss : 0.6646866798400879\n",
      "Epoch : 2500, Loss : 0.6709294319152832\n",
      "Epoch : 2600, Loss : 0.6664636731147766\n",
      "Epoch : 2700, Loss : 0.6667084097862244\n",
      "Epoch : 2800, Loss : 0.6660972833633423\n",
      "Epoch : 2900, Loss : 0.668111264705658\n",
      "Epoch : 3000, Loss : 0.6663311123847961\n",
      "torch.Size([1886])\n",
      "Epoch : 100, Loss : 0.6862214207649231\n",
      "Epoch : 200, Loss : 0.6798649430274963\n",
      "Epoch : 300, Loss : 0.6804203391075134\n",
      "Epoch : 400, Loss : 0.6782620549201965\n",
      "Epoch : 500, Loss : 0.6820824146270752\n",
      "Epoch : 600, Loss : 0.6806555390357971\n",
      "Epoch : 700, Loss : 0.6845495700836182\n",
      "Epoch : 800, Loss : 0.6820342540740967\n",
      "Epoch : 900, Loss : 0.6789280772209167\n",
      "Epoch : 1000, Loss : 0.6846038103103638\n",
      "Epoch : 1100, Loss : 0.6801154017448425\n",
      "Epoch : 1200, Loss : 0.6803970336914062\n",
      "Epoch : 1300, Loss : 0.6820517778396606\n",
      "Epoch : 1400, Loss : 0.6842664480209351\n",
      "Epoch : 1500, Loss : 0.6794272661209106\n",
      "Epoch : 1600, Loss : 0.6795719861984253\n",
      "Epoch : 1700, Loss : 0.6828827261924744\n",
      "Epoch : 1800, Loss : 0.679015040397644\n",
      "Epoch : 1900, Loss : 0.6964858174324036\n",
      "Epoch : 2000, Loss : 0.6808016896247864\n",
      "Epoch : 2100, Loss : 0.6800984740257263\n",
      "Epoch : 2200, Loss : 0.6764451265335083\n",
      "Epoch : 2300, Loss : 0.6794945597648621\n",
      "Epoch : 2400, Loss : 0.6741944551467896\n",
      "Epoch : 2500, Loss : 0.6718546152114868\n",
      "Epoch : 2600, Loss : 0.6676167249679565\n",
      "Epoch : 2700, Loss : 0.6586249470710754\n",
      "Epoch : 2800, Loss : 0.6382759213447571\n",
      "Epoch : 2900, Loss : 0.59703528881073\n",
      "Epoch : 3000, Loss : 0.5931956768035889\n",
      "torch.Size([644])\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    # if i == 2 :\n",
    "    #     n_epochs = 2000\n",
    "    # else :\n",
    "    #     n_epochs = 500\n",
    "    n_epochs = 3000\n",
    "    model = training_loop(data = train_pyg[i], n_epochs = n_epochs)\n",
    "    # pred = predict(model, test_pyg[i])\n",
    "\n",
    "    z = model.encode(test_pyg[i].x, test_pyg[i].edge_index)\n",
    "    pred = torch.sigmoid(model.decode(z, test_pyg[i].edge_label_index))\n",
    "    print(pred.shape)\n",
    "    pred = pd.DataFrame(pred.cpu().detach().numpy())\n",
    "    pred = pd.concat([test_[i], pred], axis = 1)\n",
    "    pred = pred.drop(['to', 'from'], axis = 1)\n",
    "    pred.columns = ['id', 'prob']\n",
    "    pred.to_csv('./upload/pred_pyg_entropy_{}.csv'.format(i + 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_data, model):\n",
    "    z = model.encode(test_data.x, test_data.edge_index)\n",
    "    test_pred = torch.sigmoid(model.decode(z, test_data.edge_label_index))\n",
    "    return test_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterlab",
   "language": "python",
   "name": "jupyterlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
